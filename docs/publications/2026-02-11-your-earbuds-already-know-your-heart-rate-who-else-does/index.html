<!DOCTYPE html><html lang="en-US" data-theme="light"> <head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="description" content="28 ways consumer sensors extract biometric, physiological, and cognitive data without dedicated health hardware, and why the attack chain ends at your brain"><link rel="canonical" href="https://qinnovate.com/publications/2026-02-11-your-earbuds-already-know-your-heart-rate-who-else-does/"><!-- Favicon --><link rel="icon" type="image/svg+xml" href="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 100 100'%3E%3Ctext y='.9em' font-size='90' font-family='system-ui' fill='%2306b6d4'%3EQ%3C/text%3E%3C/svg%3E"><!-- Open Graph --><meta property="og:title" content="Your Headphones Know Your Heart Rate — Even Without a Heart Rate Sensor"><meta property="og:description" content="28 ways consumer sensors extract biometric, physiological, and cognitive data without dedicated health hardware, and why the attack chain ends at your brain"><meta property="og:url" content="https://qinnovate.com/publications/2026-02-11-your-earbuds-already-know-your-heart-rate-who-else-does/"><meta property="og:site_name" content="Qinnovate"><meta property="og:type" content="article"><meta property="og:image" content="https://qinnovate.com/images/og-default.png"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="630"><meta property="og:locale" content="en_US"><meta property="article:published_time" content="2026-02-11T00:00:00.000Z"><meta property="article:author" content="Qinnovate"><meta property="article:tag" content="#TARA"><meta property="article:tag" content="#NeurosecurityEngineering"><meta property="article:tag" content="#QIF"><meta property="article:tag" content="#BCI"><meta property="article:tag" content="#ConsumerSensors"><meta property="article:tag" content="#SDomain"><meta property="article:tag" content="#Biometrics"><meta property="article:tag" content="#Privacy"><meta property="article:tag" content="#SensorExploitation"><!-- Twitter Card --><meta name="twitter:card" content="summary_large_image"><meta name="twitter:title" content="Your Headphones Know Your Heart Rate — Even Without a Heart Rate Sensor"><meta name="twitter:description" content="28 ways consumer sensors extract biometric, physiological, and cognitive data without dedicated health hardware, and why the attack chain ends at your brain"><meta name="twitter:image" content="https://qinnovate.com/images/og-default.png"><meta name="twitter:creator" content="@qikevinl"><!-- JSON-LD Structured Data --><script type="application/ld+json">{"@context":"https://schema.org","@type":"Organization","name":"Qinnovate","url":"https://qinnovate.com","description":"Open standards and frameworks for brain-computer interface security.","foundingDate":"2026","sameAs":["https://github.com/qinnovates"]}</script><script type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Home","item":"https://qinnovate.com/"},{"@type":"ListItem","position":2,"name":"News","item":"https://qinnovate.com/news/"},{"@type":"ListItem","position":3,"name":"Your Headphones Know Your Heart Rate — Even Without a Heart Rate Sensor"}]}</script><!-- RSS autodiscovery --><link rel="alternate" type="application/rss+xml" title="Qinnovate Intel" href="/rss.xml"><title>Your Headphones Know Your Heart Rate — Even Without a Heart Rate Sensor | Qinnovate</title><!-- View Transitions --><meta name="astro-view-transitions-enabled" content="true"><meta name="astro-view-transitions-fallback" content="animate"><script type="module" src="/_astro/ClientRouter.astro_astro_type_script_index_0_lang.CDGfc0hd.js"></script><!-- Google Analytics 4 --><script async src="https://www.googletagmanager.com/gtag/js?id=G-DKB9RWW0C2"></script><script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-DKB9RWW0C2');
  </script><!-- Theme initialization (prevent flash) --><script>
    (function(){ document.documentElement.setAttribute('data-theme', 'light'); })();
  </script><link rel="stylesheet" href="/_astro/TARA.w5QsKvtK.css">
<link rel="stylesheet" href="/_astro/TARA.C_iNMcSg.css"></head> <body class="min-h-screen">  <nav class="glass fixed top-0 left-0 right-0 z-50 border-b border-[var(--color-border)]" id="main-nav" data-astro-transition-persist="astro-zscz5gm2-1"> <div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8"> <div class="flex items-center justify-between h-16"> <!-- Logo --> <a href="/" class="flex items-center gap-2 hover:opacity-80 transition-opacity"> <span class="text-2xl font-bold font-[family-name:var(--font-heading)] bg-gradient-to-r from-[var(--color-accent-primary)] via-[var(--color-accent-secondary)] to-[var(--color-accent-tertiary)] bg-clip-text text-transparent">Q</span> <span class="text-sm font-medium tracking-wider uppercase hidden sm:inline text-[var(--color-text-primary)]">innovate</span> </a> <!-- Desktop links --> <div class="hidden md:flex items-center gap-1"> <!-- About (flat link) --> <a href="/about/" class="px-3 py-2 rounded-lg text-sm font-medium transition-colors text-[var(--color-text-muted)] hover:text-[var(--color-text-primary)] hover:bg-black/5">
About
</a> <!-- Technology dropdown --> <div class="relative" data-dropdown="tech"> <button class="flex items-center gap-1 px-3 py-2 rounded-lg text-sm font-medium transition-colors text-[var(--color-text-muted)] hover:text-[var(--color-text-primary)] hover:bg-black/5">
Technology
<svg class="w-3.5 h-3.5 opacity-60" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2"> <path stroke-linecap="round" stroke-linejoin="round" d="M19.5 8.25l-7.5 7.5-7.5-7.5"></path> </svg> </button> <div class="dropdown-menu absolute left-0 top-full pt-2 hidden"> <div class="glass rounded-xl border border-[var(--color-border)] shadow-xl w-72 overflow-hidden"> <div class="p-2"> <a href="/framework/" class="block px-3 py-2.5 rounded-lg transition-colors text-[var(--color-text-muted)] hover:text-[var(--color-text-primary)] hover:bg-black/5"> <span class="text-sm font-medium block leading-snug">QIF Framework</span> <span class="text-xs text-[var(--color-text-faint)] block mt-0.5 leading-snug">The 11-band hourglass governance architecture</span> </a><a href="/nsp/" class="block px-3 py-2.5 rounded-lg transition-colors text-[var(--color-text-muted)] hover:text-[var(--color-text-primary)] hover:bg-black/5"> <span class="text-sm font-medium block leading-snug">NSP Protocol</span> <span class="text-xs text-[var(--color-text-faint)] block mt-0.5 leading-snug">Secure communication protocol for patient safety and privacy</span> </a><a href="/runemate/" class="block px-3 py-2.5 rounded-lg transition-colors text-[var(--color-text-muted)] hover:text-[var(--color-text-primary)] hover:bg-black/5"> <span class="text-sm font-medium block leading-snug">Runemate</span> <span class="text-xs text-[var(--color-text-faint)] block mt-0.5 leading-snug">Compiler enabling on-device security for neural implants</span> </a><a href="/TARA/" class="block px-3 py-2.5 rounded-lg transition-colors text-[var(--color-text-muted)] hover:text-[var(--color-text-primary)] hover:bg-black/5"> <span class="text-sm font-medium block leading-snug">TARA</span> <span class="text-xs text-[var(--color-text-faint)] block mt-0.5 leading-snug">Risk taxonomy — attacks, ethical risks, and therapeutic applications</span> </a><a href="/whitepaper/" class="block px-3 py-2.5 rounded-lg transition-colors text-[var(--color-text-muted)] hover:text-[var(--color-text-primary)] hover:bg-black/5"> <span class="text-sm font-medium block leading-snug">Whitepaper</span> <span class="text-xs text-[var(--color-text-faint)] block mt-0.5 leading-snug">Full QIF specification document</span> </a> </div> </div> </div> </div> <!-- Resources dropdown --> <div class="relative" data-dropdown="resources"> <button class="flex items-center gap-1 px-3 py-2 rounded-lg text-sm font-medium transition-colors text-[var(--color-accent-primary)] bg-[var(--color-accent-primary)]/10">
Resources
<svg class="w-3.5 h-3.5 opacity-60" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2"> <path stroke-linecap="round" stroke-linejoin="round" d="M19.5 8.25l-7.5 7.5-7.5-7.5"></path> </svg> </button> <div class="dropdown-menu absolute left-0 top-full pt-2 hidden"> <div class="glass rounded-xl border border-[var(--color-border)] shadow-xl w-64 overflow-hidden"> <div class="p-2"> <a href="/news/" class="block px-3 py-2.5 rounded-lg transition-colors text-[var(--color-accent-primary)] bg-[var(--color-accent-primary)]/10"> <span class="text-sm font-medium block leading-snug">News</span> <span class="text-xs text-[var(--color-text-faint)] block mt-0.5 leading-snug">Latest publications and updates</span> </a><a href="/explore/" class="block px-3 py-2.5 rounded-lg transition-colors text-[var(--color-text-muted)] hover:text-[var(--color-text-primary)] hover:bg-black/5"> <span class="text-sm font-medium block leading-snug">Explore</span> <span class="text-xs text-[var(--color-text-faint)] block mt-0.5 leading-snug">Interactive visualizations and tools</span> </a><a href="/glossary/" class="block px-3 py-2.5 rounded-lg transition-colors text-[var(--color-text-muted)] hover:text-[var(--color-text-primary)] hover:bg-black/5"> <span class="text-sm font-medium block leading-snug">Glossary</span> <span class="text-xs text-[var(--color-text-faint)] block mt-0.5 leading-snug">QIF terminology reference</span> </a> </div> </div> </div> </div> <!-- Engage dropdown --> <div class="relative" data-dropdown="engage"> <button class="flex items-center gap-1 px-3 py-2 rounded-lg text-sm font-medium transition-colors text-[var(--color-text-muted)] hover:text-[var(--color-text-primary)] hover:bg-black/5">
Engage
<svg class="w-3.5 h-3.5 opacity-60" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2"> <path stroke-linecap="round" stroke-linejoin="round" d="M19.5 8.25l-7.5 7.5-7.5-7.5"></path> </svg> </button> <div class="dropdown-menu absolute left-0 top-full pt-2 hidden"> <div class="glass rounded-xl border border-[var(--color-border)] shadow-xl w-72 overflow-hidden"> <div class="p-2"> <a href="/adopt/" class="block px-3 py-2.5 rounded-lg transition-colors text-[var(--color-text-muted)] hover:text-[var(--color-text-primary)] hover:bg-black/5"> <span class="text-sm font-medium block leading-snug">Adopt the Standard</span> <span class="text-xs text-[var(--color-text-faint)] block mt-0.5 leading-snug">Integrate QIF into your organization or research</span> </a><a href="/advisory/" class="block px-3 py-2.5 rounded-lg transition-colors text-[var(--color-text-muted)] hover:text-[var(--color-text-primary)] hover:bg-black/5"> <span class="text-sm font-medium block leading-snug">Advisory Services</span> <span class="text-xs text-[var(--color-text-faint)] block mt-0.5 leading-snug">Hands-on guidance for BCI security implementation</span> </a><a href="https://github.com/qinnovates/qinnovate" target="_blank" rel="noopener noreferrer" class="block px-3 py-2.5 rounded-lg transition-colors text-[var(--color-text-muted)] hover:text-[var(--color-text-primary)] hover:bg-black/5"> <span class="text-sm font-medium block leading-snug">Get Involved</span> <span class="text-xs text-[var(--color-text-faint)] block mt-0.5 leading-snug">Contribute on GitHub — issues, PRs, discussions</span> </a> </div> </div> </div> </div> <!-- Governance dropdown --> <div class="relative" data-dropdown="gov"> <a href="/governance/" class="flex items-center gap-1 px-3 py-2 rounded-lg text-sm font-medium transition-colors text-[var(--color-text-muted)] hover:text-[var(--color-text-primary)] hover:bg-black/5">
Governance
<svg class="w-3.5 h-3.5 opacity-60" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2"> <path stroke-linecap="round" stroke-linejoin="round" d="M19.5 8.25l-7.5 7.5-7.5-7.5"></path> </svg> </a> <div class="dropdown-menu absolute right-0 top-full pt-2 hidden"> <div class="glass rounded-xl border border-[var(--color-border)] shadow-xl w-72 overflow-hidden"> <div class="p-2"> <a href="/governance/#core" class="block px-3 py-2.5 rounded-lg transition-colors text-[var(--color-text-muted)] hover:text-[var(--color-text-primary)] hover:bg-black/5"> <span class="text-sm font-medium block leading-snug">Core Standards</span> <span class="text-xs text-[var(--color-text-faint)] block mt-0.5 leading-snug">Code of Conduct, Transparency, Data Policy, Accessibility</span> </a><a href="/governance/#ethics" class="block px-3 py-2.5 rounded-lg transition-colors text-[var(--color-text-muted)] hover:text-[var(--color-text-primary)] hover:bg-black/5"> <span class="text-sm font-medium block leading-snug">Ethics &amp; Rights</span> <span class="text-xs text-[var(--color-text-faint)] block mt-0.5 leading-snug">Neuroethics, Informed Consent, Pediatric, Post-Deployment</span> </a><a href="/governance/#compliance" class="block px-3 py-2.5 rounded-lg transition-colors text-[var(--color-text-muted)] hover:text-[var(--color-text-primary)] hover:bg-black/5"> <span class="text-sm font-medium block leading-snug">Compliance</span> <span class="text-xs text-[var(--color-text-faint)] block mt-0.5 leading-snug">Regulatory, UNESCO Alignment, QIF Neuroethics</span> </a> </div> </div> </div> </div> </div> <!-- Right side --> <div class="flex items-center gap-3"> <!-- GitHub link --> <a href="https://github.com/qinnovates/qinnovate" target="_blank" rel="noopener noreferrer" class="p-2 rounded-lg text-[var(--color-text-muted)] hover:text-[var(--color-text-primary)] hover:bg-black/5 transition-colors" aria-label="GitHub"> <svg class="w-5 h-5" fill="currentColor" viewBox="0 0 24 24"> <path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"></path> </svg> </a> <!-- Search button --> <button id="search-btn" class="p-2 rounded-lg text-[var(--color-text-muted)] hover:text-[var(--color-text-primary)] hover:bg-black/5 transition-colors" aria-label="Search"> <svg class="w-5 h-5" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2"> <path stroke-linecap="round" stroke-linejoin="round" d="M21 21l-5.197-5.197m0 0A7.5 7.5 0 105.196 5.196a7.5 7.5 0 0010.607 10.607z"></path> </svg> </button> <!-- Mobile menu button --> <button id="mobile-menu-btn" class="md:hidden p-2 rounded-lg text-[var(--color-text-muted)] hover:text-[var(--color-text-primary)] hover:bg-black/5 transition-colors" aria-label="Open menu" aria-expanded="false"> <svg class="w-5 h-5" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2"> <path stroke-linecap="round" stroke-linejoin="round" d="M4 6h16M4 12h16M4 18h16"></path> </svg> </button> </div> </div> </div> <!-- Mobile menu --> <div id="mobile-menu" class="md:hidden hidden border-t border-[var(--color-border)]"> <div class="px-4 py-3 space-y-1"> <!-- About (flat) --> <a href="/about/" class="block px-3 py-2 rounded-lg text-sm font-medium transition-colors text-[var(--color-text-muted)] hover:text-[var(--color-text-primary)] hover:bg-black/5">
About
</a> <!-- Mobile Technology section --> <div> <button data-mobile-toggle="tech" class="flex items-center justify-between w-full px-3 py-2 rounded-lg text-sm font-medium transition-colors text-[var(--color-text-muted)] hover:text-[var(--color-text-primary)] hover:bg-black/5">
Technology
<svg class="w-3.5 h-3.5 opacity-60 transition-transform" data-chevron="tech" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2"> <path stroke-linecap="round" stroke-linejoin="round" d="M19.5 8.25l-7.5 7.5-7.5-7.5"></path> </svg> </button> <div data-mobile-list="tech" class="hidden pl-3 space-y-0.5 mt-1"> <a href="/framework/" class="block px-3 py-1.5 rounded-lg text-sm transition-colors text-[var(--color-text-faint)] hover:text-[var(--color-text-primary)]"> QIF Framework </a><a href="/nsp/" class="block px-3 py-1.5 rounded-lg text-sm transition-colors text-[var(--color-text-faint)] hover:text-[var(--color-text-primary)]"> NSP Protocol </a><a href="/runemate/" class="block px-3 py-1.5 rounded-lg text-sm transition-colors text-[var(--color-text-faint)] hover:text-[var(--color-text-primary)]"> Runemate </a><a href="/TARA/" class="block px-3 py-1.5 rounded-lg text-sm transition-colors text-[var(--color-text-faint)] hover:text-[var(--color-text-primary)]"> TARA </a><a href="/whitepaper/" class="block px-3 py-1.5 rounded-lg text-sm transition-colors text-[var(--color-text-faint)] hover:text-[var(--color-text-primary)]"> Whitepaper </a> </div> </div> <!-- Mobile Resources section --> <div> <button data-mobile-toggle="resources" class="flex items-center justify-between w-full px-3 py-2 rounded-lg text-sm font-medium transition-colors text-[var(--color-accent-primary)] bg-[var(--color-accent-primary)]/10">
Resources
<svg class="w-3.5 h-3.5 opacity-60 transition-transform" data-chevron="resources" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2"> <path stroke-linecap="round" stroke-linejoin="round" d="M19.5 8.25l-7.5 7.5-7.5-7.5"></path> </svg> </button> <div data-mobile-list="resources" class="hidden pl-3 space-y-0.5 mt-1"> <a href="/news/" class="block px-3 py-1.5 rounded-lg text-sm transition-colors text-[var(--color-accent-primary)]"> News </a><a href="/explore/" class="block px-3 py-1.5 rounded-lg text-sm transition-colors text-[var(--color-text-faint)] hover:text-[var(--color-text-primary)]"> Explore </a><a href="/glossary/" class="block px-3 py-1.5 rounded-lg text-sm transition-colors text-[var(--color-text-faint)] hover:text-[var(--color-text-primary)]"> Glossary </a> </div> </div> <!-- Mobile Engage section --> <div> <button data-mobile-toggle="engage" class="flex items-center justify-between w-full px-3 py-2 rounded-lg text-sm font-medium transition-colors text-[var(--color-text-muted)] hover:text-[var(--color-text-primary)] hover:bg-black/5">
Engage
<svg class="w-3.5 h-3.5 opacity-60 transition-transform" data-chevron="engage" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2"> <path stroke-linecap="round" stroke-linejoin="round" d="M19.5 8.25l-7.5 7.5-7.5-7.5"></path> </svg> </button> <div data-mobile-list="engage" class="hidden pl-3 space-y-0.5 mt-1"> <a href="/adopt/" class="block px-3 py-1.5 rounded-lg text-sm transition-colors text-[var(--color-text-faint)] hover:text-[var(--color-text-primary)]"> Adopt the Standard </a><a href="/advisory/" class="block px-3 py-1.5 rounded-lg text-sm transition-colors text-[var(--color-text-faint)] hover:text-[var(--color-text-primary)]"> Advisory Services </a><a href="https://github.com/qinnovates/qinnovate" target="_blank" rel="noopener noreferrer" class="block px-3 py-1.5 rounded-lg text-sm transition-colors text-[var(--color-text-faint)] hover:text-[var(--color-text-primary)]"> Get Involved </a> </div> </div> <!-- Mobile Governance section --> <div class="pt-2 border-t border-[var(--color-border)] mt-2"> <button data-mobile-toggle="gov" class="flex items-center justify-between w-full px-3 py-2 rounded-lg text-sm font-medium transition-colors text-[var(--color-text-muted)] hover:text-[var(--color-text-primary)] hover:bg-black/5">
Governance
<svg class="w-3.5 h-3.5 opacity-60 transition-transform" data-chevron="gov" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2"> <path stroke-linecap="round" stroke-linejoin="round" d="M19.5 8.25l-7.5 7.5-7.5-7.5"></path> </svg> </button> <div data-mobile-list="gov" class="hidden pl-3 space-y-0.5 mt-1"> <a href="/governance/#core" class="block px-3 py-1.5 rounded-lg text-sm transition-colors text-[var(--color-text-faint)] hover:text-[var(--color-text-primary)]"> Core Standards </a><a href="/governance/#ethics" class="block px-3 py-1.5 rounded-lg text-sm transition-colors text-[var(--color-text-faint)] hover:text-[var(--color-text-primary)]"> Ethics &amp; Rights </a><a href="/governance/#compliance" class="block px-3 py-1.5 rounded-lg text-sm transition-colors text-[var(--color-text-faint)] hover:text-[var(--color-text-primary)]"> Compliance </a> </div> </div> </div> </div> </nav> <!-- Search modal --> <div id="search-modal" class="fixed inset-0 z-[100] hidden"> <div id="search-backdrop" class="absolute inset-0 bg-black/60 backdrop-blur-sm"></div> <div class="relative max-w-2xl mx-auto mt-20 px-4"> <div class="glass rounded-xl p-4 shadow-2xl" id="search-container"> <div id="search" class="pagefind-ui pagefind-init" data-pagefind-ui data-bundle-path="/pagefind/" data-ui-options="{&#34;showImages&#34;:false,&#34;showSubResults&#34;:true}"></div> <script type="module" src="/_astro/Search.astro_astro_type_script_index_0_lang.tZYucdM2.js"></script> </div> </div> </div> <script type="module">function u(){const n=document.getElementById("mobile-menu-btn"),i=document.getElementById("mobile-menu");n?.addEventListener("click",()=>{const e=n.getAttribute("aria-expanded")==="true";n.setAttribute("aria-expanded",String(!e)),i?.classList.toggle("hidden")}),document.addEventListener("astro:before-swap",()=>{i?.classList.add("hidden"),n?.setAttribute("aria-expanded","false")}),document.querySelectorAll("[data-dropdown]").forEach(e=>{const t=e.querySelector(".dropdown-menu");let a;function c(){document.querySelectorAll(".dropdown-menu").forEach(o=>{o!==t&&o.classList.add("hidden")}),clearTimeout(a),t?.classList.remove("hidden")}function l(){a=setTimeout(()=>{t?.classList.add("hidden")},150)}e.addEventListener("mouseenter",c),e.addEventListener("mouseleave",l),e.addEventListener("focusin",c),e.addEventListener("focusout",o=>{e.contains(o.relatedTarget)||l()})}),document.querySelectorAll("[data-mobile-toggle]").forEach(e=>{const t=e.getAttribute("data-mobile-toggle"),a=document.querySelector(`[data-mobile-list="${t}"]`),c=document.querySelector(`[data-chevron="${t}"]`);e.addEventListener("click",()=>{a?.classList.toggle("hidden"),c?.classList.toggle("rotate-180")})});const m=document.getElementById("search-btn"),d=document.getElementById("search-modal"),h=document.getElementById("search-backdrop");function r(){d?.classList.remove("hidden"),setTimeout(()=>{d?.querySelector(".pagefind-ui__search-input")?.focus()},50)}function s(){d?.classList.add("hidden")}m?.addEventListener("click",r),h?.addEventListener("click",s),document.addEventListener("keydown",e=>{(e.metaKey||e.ctrlKey)&&e.key==="k"&&(e.preventDefault(),d?.classList.contains("hidden")?r():s()),e.key==="Escape"&&s()}),document.addEventListener("astro:before-swap",s)}u();document.addEventListener("astro:after-swap",u);</script> <article class="max-w-4xl mx-auto px-4 sm:px-6 lg:px-8 pt-24 pb-16"> <script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","headline":"Your Headphones Know Your Heart Rate — Even Without a Heart Rate Sensor","description":"28 ways consumer sensors extract biometric, physiological, and cognitive data without dedicated health hardware, and why the attack chain ends at your brain","datePublished":"2026-02-11T00:00:00.000Z","author":{"@type":"Organization","name":"Qinnovate","url":"https://qinnovate.com"},"publisher":{"@type":"Organization","name":"Qinnovate","url":"https://qinnovate.com"},"mainEntityOfPage":"https://qinnovate.com/publications/2026-02-11-your-earbuds-already-know-your-heart-rate-who-else-does/"}</script> <nav aria-label="Breadcrumb" class="text-sm text-[var(--color-text-faint)] mb-6"> <ol class="flex items-center gap-2 flex-wrap"> <li> <a href="/" class="hover:text-[var(--color-accent-primary)] transition-colors">Home</a> </li>  <li aria-hidden="true" class="select-none">/</li> <li> <a href="/news/" class="hover:text-[var(--color-accent-primary)] transition-colors"> News </a> </li>  <li aria-hidden="true" class="select-none">/</li> <li> <span class="text-[var(--color-text-muted)]">Your Headphones Know Your Heart Rate — Even Without a Heart Rate Sensor</span> </li>  </ol> </nav> <!-- Article header --> <header class="mb-12"> <h1 class="text-3xl sm:text-4xl font-bold font-[family-name:var(--font-heading)] leading-tight mb-4"> Your Headphones Know Your Heart Rate — Even Without a Heart Rate Sensor </h1> <p class="text-lg text-[var(--color-text-muted)] mb-6 italic">28 ways consumer sensors extract biometric, physiological, and cognitive data without dedicated health hardware, and why the attack chain ends at your brain</p> <div class="flex flex-wrap items-center gap-4 text-sm text-[var(--color-text-faint)]"> <time datetime="2026-02-11T00:00:00.000Z">February 10, 2026</time>  <span>&middot;</span> <a href="https://qinnovate.com" target="_blank" rel="noopener noreferrer" class="hover:text-[var(--color-accent-primary)] transition-colors">
Original source
</a>  </div> <div class="flex flex-wrap gap-2 mt-4"> <span class="text-xs px-2 py-1 rounded-full bg-[var(--color-bg-elevated)] text-[var(--color-text-muted)]"> tara </span><span class="text-xs px-2 py-1 rounded-full bg-[var(--color-bg-elevated)] text-[var(--color-text-muted)]"> neurosecurityengineering </span><span class="text-xs px-2 py-1 rounded-full bg-[var(--color-bg-elevated)] text-[var(--color-text-muted)]"> qif </span><span class="text-xs px-2 py-1 rounded-full bg-[var(--color-bg-elevated)] text-[var(--color-text-muted)]"> bci </span><span class="text-xs px-2 py-1 rounded-full bg-[var(--color-bg-elevated)] text-[var(--color-text-muted)]"> consumersensors </span><span class="text-xs px-2 py-1 rounded-full bg-[var(--color-bg-elevated)] text-[var(--color-text-muted)]"> sdomain </span><span class="text-xs px-2 py-1 rounded-full bg-[var(--color-bg-elevated)] text-[var(--color-text-muted)]"> biometrics </span><span class="text-xs px-2 py-1 rounded-full bg-[var(--color-bg-elevated)] text-[var(--color-text-muted)]"> privacy </span><span class="text-xs px-2 py-1 rounded-full bg-[var(--color-bg-elevated)] text-[var(--color-text-muted)]"> sensorexploitation </span> </div> </header> <!-- Article body --> <div class="prose">  <h2 id="your-20-headphones-are-a-medical-device">Your $20 Headphones Are a Medical Device</h2>
<p>You do not need AirPods Pro with a health sensor. You do not need a Pixel Watch with PPG. A pair of ten-year-old wired headphones plugged into a laptop can measure your heart rate.</p>
<p>The speaker driver in any headphone is a diaphragm attached to a coil. That is the same physical mechanism as a microphone, just running in reverse. RealTek HD Audio codecs — present in the majority of PCs and laptops shipped in the last fifteen years — allow any software process to silently reprogram an output jack as an input jack. No permission dialog. No notification. No elevated privileges. The headphone you are wearing right now becomes a microphone pointed at your ear canal. From there, your pulse is an acoustic signal.</p>
<p>That is one technique out of 28.</p>
<p>Your phone measures your heart rate through its camera. It knows your gait from its accelerometer. It can detect Parkinson’s tremor from the way your hand shakes while you type. It captures your breathing pattern through inaudible ultrasonic pulses from its speaker. It fingerprints you through Bluetooth radio imperfections that no software update can change.</p>
<p>None of this requires a brain-computer interface. None of it requires a medical implant. None of it requires dedicated health hardware. None of it requires your permission.</p>
<p>The average consumer carries a smartphone, a smartwatch, and a pair of headphones. Together, those three devices contain more than ten sensors: accelerometers, gyroscopes, magnetometers, barometers, cameras, microphones, ambient light sensors, proximity sensors, WiFi radios, Bluetooth transmitters. Some have PPG optical heart rate monitors. Most do not. It does not matter. Each sensor has a legitimate purpose. Each sensor has a second purpose that nobody consented to — and that second purpose does not depend on the sensor being designed for health.</p>
<p>We spent the last two weeks mapping those second purposes. The result is 28 techniques across four tactical categories in what we call the S-domain: Consumer Sensor Exploitation.</p>
<p>Today the TARA registry reaches 99 techniques.</p>
<h2 id="what-the-s-domain-covers">What the S-Domain Covers</h2>
<p>The <a href="https://qinnovate.com/TARA">TARA framework</a> (Therapeutic Atlas of Risks and Applications) classifies attacks against brain-computer interfaces across eight operational domains. Seven of those domains cover threats that touch neural tissue, BCI hardware, cognitive processes, or the data pipeline between them.</p>
<p>The eighth domain is different. It covers the consumer devices that billions of people already carry, devices that sit upstream of any neural interface in the kill chain.</p>
<p>We organized the 28 techniques into four tactics:</p>
<p><strong>Sensor Repurposing (S.RP):</strong> Using a sensor for something it was not designed to do. Your gyroscope was designed to detect rotation. <a href="https://www.usenix.org/conference/usenixsecurity14/technical-sessions/presentation/michalevsky">Michalevsky et al. (2014)</a> showed it can record speech. Your speaker was designed to produce sound. <a href="https://www.usenix.org/conference/woot17/workshop-program/presentation/guri">Guri et al. (2017)</a> showed it can be reprogrammed to function as a microphone (that one became <a href="https://qinnovate.com/blog/2026-02-11-tara-first-cve-realtek-audio-jack-retasking">our first CVE</a>). Your earbuds were designed for audio. <a href="https://pubmed.ncbi.nlm.nih.gov/31425018/">Kaveh et al. (2020)</a> showed that a conductive ear tip turns them into an EEG recorder.</p>
<p><strong>Sensor Fingerprinting (S.FP):</strong> Using sensor data to identify you. Your ear canal has a unique acoustic signature (<a href="https://www.nec.com/en/press/201603/global_20160307_02.html">NEC Corporation, 2016</a>). Your walking pattern is as distinctive as a fingerprint (<a href="https://ieeexplore.ieee.org/document/7893786">Muaaz &#x26; Mayrhofer, 2017</a>). Your cardiac pulse waveform is unique to your cardiovascular anatomy (<a href="https://ieeexplore.ieee.org/document/8567966">Biswas et al., 2019</a>). Your Bluetooth radio has manufacturing imperfections that identify your specific device even when MAC address randomization is enabled (<a href="https://petsymposium.org/popets/2022/popets-2022-0003.php">Becker et al., 2022</a>).</p>
<p><strong>Sensor Harvest (S.HV):</strong> Extracting physiological or cognitive data through sensors. A webcam extracts your heart rate from sub-pixel skin color changes (<a href="https://arxiv.org/abs/1805.07888">Chen &#x26; McDuff, 2018</a>). A WiFi router detects your breathing through walls (<a href="https://dl.acm.org/doi/10.1145/3386901.3388905">Zeng et al., 2020</a>). Your phone’s motion sensors reveal whether you have a neurological condition like Parkinson’s disease (<a href="https://www.nature.com/articles/sdata201611">Bot et al., 2016</a>). An AR headset’s eye tracker infers your cognitive state, emotional arousal, and potentially your sexual orientation from gaze patterns (<a href="https://dl.acm.org/doi/10.1145/3383123">Katsini et al., 2020</a>).</p>
<p><strong>Sensor Chaining (S.CH):</strong> Combining multiple sensor exploits into compound attack chains. This is where it gets interesting.</p>
<h2 id="the-chain-techniques">The Chain Techniques</h2>
<p>Individual sensor exploits are concerning. Chained together, they become something qualitatively different.</p>
<p>Consider a pair of earbuds. Not smart earbuds. Not health earbuds. Any earbuds with a speaker and a wire or Bluetooth radio. A single device. What it can do, step by step:</p>
<p><strong>Step 1:</strong> The speaker is reprogrammed as a microphone (T0072). The attacker has ambient audio. Everything said in the room.</p>
<p><strong>Step 2:</strong> The ANC system’s probe tones fingerprint the ear canal (T0079). The attacker knows who is wearing the earbuds. Silent, passive identification every time the earbuds are inserted.</p>
<p><strong>Step 3:</strong> A conductive ear tip and a sub-$5 biopotential amplifier hidden in the housing capture in-ear EEG from temporal cortex (T0073). The attacker has continuous neural telemetry.</p>
<p><strong>Step 4:</strong> A machine learning model trained on weeks of that EEG data builds a personalized cognitive profile (T0074). The attacker can predict cognitive state in real time, identifying moments of low vigilance, high emotional arousal, or deep engagement.</p>
<p>The end state: identity plus ambient audio plus neural telemetry plus a personalized cognitive vulnerability map. From a device the target voluntarily wears for hours every day.</p>
<p>We documented this as T0095, the acoustic-to-neural profiling pipeline. Each step in the chain has been independently demonstrated or is actively emerging in research. The complete chain has not been demonstrated end to end. But every component exists.</p>
<h2 id="the-biometric-panopticon">The Biometric Panopticon</h2>
<p>There is a parallel chain that does not require neural data at all.</p>
<p>Your earbuds fingerprint you by ear canal acoustics (T0079). Your phone fingerprints you by gait pattern (T0088). Your watch fingerprints you by cardiac pulse waveform (T0093). Your Bluetooth radio fingerprints your device by hardware imperfections (T0091). If you wear a VR headset, your eye tracking data fingerprints you by gaze behavior (T0085).</p>
<p>Each of these biometrics works independently. Combine three and identification accuracy exceeds 99 percent. Combine four and the system maintains identification even if one channel is disrupted. You can change your earbuds. You can alter your gait. You can disable Bluetooth. You cannot do all three simultaneously, and the fusion system only needs two of four channels.</p>
<p>We documented this as T0096, the multi-modal biometric fusion attack. The individual biometrics are established research. The insight is that the average consumer already carries enough sensors for the fusion to work, and no single privacy measure can defeat the aggregate.</p>
<p>These biometrics share a property that makes them different from passwords and cookies: they are irrevocable. You cannot change your ear canal geometry. You cannot change your cardiovascular anatomy. You cannot change the manufacturing imperfections in your phone’s Bluetooth transmitter. Once captured, these identifiers track you for life.</p>
<h2 id="why-this-matters-for-brain-computer-interfaces">Why This Matters for Brain-Computer Interfaces</h2>
<p>The capstone technique in the registry is T0099: Consumer-Sensor-to-BCI Kill Chain Escalation.</p>
<p>The argument is straightforward. Before a person ever receives a brain-computer interface, whether a medical implant for Parkinson’s treatment or a consumer neural headband for meditation, an attacker who has been monitoring their consumer devices already has:</p>
<p>A <strong>behavioral baseline</strong> from months of gait, activity, and sleep data. A <strong>physiological profile</strong> from cardiac, respiratory, and neurological sensor streams. A <strong>biometric identity</strong> fused from multiple irrevocable signatures. And, if the target uses VR/AR or wears modified earbuds, a <strong>cognitive profile</strong> from eye tracking or in-ear EEG.</p>
<p>When the BCI arrives, this pre-existing intelligence makes every attack more effective. Neural injection can be calibrated to the individual’s neural baseline. Evasion of anomaly detection can be trained on their “normal.” Cognitive exploitation can target known cognitive vulnerabilities.</p>
<p>The S-domain is not a separate problem from BCI security. It is the reconnaissance phase.</p>
<h2 id="what-the-numbers-say">What the Numbers Say</h2>
<p>The TARA registry now contains 99 techniques across 15 tactics and 8 domains. The S-domain accounts for 28 of those 99 techniques, making it the largest single domain by technique count.</p>
<p>Evidence levels for the 28 S-domain techniques:</p>






























<table><thead><tr><th>Status</th><th>Count</th><th>What it means</th></tr></thead><tbody><tr><td>Demonstrated</td><td>16</td><td>Proven in published research with working implementations</td></tr><tr><td>Confirmed</td><td>5</td><td>Observed in real-world systems or products</td></tr><tr><td>Emerging</td><td>5</td><td>Active research, partial demonstrations</td></tr><tr><td>Theoretical</td><td>2</td><td>Plausible from known physics, not yet demonstrated</td></tr></tbody></table>
<p>Twenty-one of the 28 techniques have been demonstrated or confirmed. These are not speculative attacks. They are published, peer-reviewed, and in some cases commercially deployed (Google’s Nest Hub uses ultrasonic vital sign sensing; Apple’s Watch uses PPG for atrial fibrillation detection; Silverpush deployed ultrasonic cross-device tracking in 234 Android apps).</p>
<p>Every technique in the registry carries both a <a href="https://www.first.org/cvss/">CVSS v4.0</a> base vector and a <a href="https://qinnovate.com/scoring">NISS v1.0</a> neural impact extension vector. An observation from the scoring: NISS scores remain low for most S-domain techniques (1.4 to 5.0 out of 10.0), because NISS measures neural safety impact and most consumer sensor attacks do not directly damage neural tissue. CVSS scores are high (confidentiality violation, data theft). The gap between the two scores is largest in the S-domain, which validates the dual-scoring approach. CVSS alone would miss the BCI-specific risks. NISS alone would miss the consumer privacy risks. You need both.</p>
<h2 id="what-you-can-do-about-it">What You Can Do About It</h2>
<p>For individuals: review sensor permissions on your devices. Motion sensor access (accelerometer, gyroscope) required no permission on Android until API level 33. Ambient light sensors still require no permission on most platforms. Microphone permission gates acoustic attacks but not ultrasonic beacon detection through other apps that already have mic access.</p>
<p>For device manufacturers: lock sensor access behind explicit permissions. Rate-limit high-frequency sensor sampling when the accessed data could reconstruct speech or keystrokes. Implement firmware attestation on audio codecs (the RealTek vulnerability that became our first CVE exists because jack retasking requires no authorization). Add physical-layer randomization to Bluetooth transmitters to prevent RF fingerprinting.</p>
<p>For policymakers: the EU AI Act’s provisions on emotion recognition systems and biometric identification apply to several techniques in this registry. The Illinois Biometric Information Privacy Act (BIPA) applies to ear canal fingerprinting, gait biometrics, and PPG waveform identification. But no current regulation addresses the aggregate: the multi-modal biometric fusion that combines individually regulated data streams into a surveillance capability that exceeds the sum of its parts.</p>
<p>For researchers: the full TARA registry is machine-readable JSON, available in the <a href="https://github.com/qinnovates/qinnovate">QIF repository</a>. Every technique entry includes sources, evidence status, CVSS and NISS scores, clinical dual-use mappings, and governance requirements. If you are working on sensor security, privacy-preserving sensing, or BCI security, the registry is designed to be built upon.</p>
<h2 id="the-map-before-the-territory">The Map Before the Territory</h2>
<p>We are mapping attack surfaces that mostly do not have defenses yet. The consumer sensor ecosystem formed around utility: step counting, heart rate monitoring, noise cancellation, augmented reality. Security was not part of the design because the sensors were not considered threats.</p>
<p>They are threats. Not because the sensors are malicious, but because they are capable. The same PPG sensor that detects atrial fibrillation (FDA-cleared, genuinely life-saving) also captures a biometric that identifies you for life. The same eye tracker that enables foveated rendering in VR (a legitimate performance optimization) also infers your cognitive state, your emotional arousal, and your attention patterns. The same WiFi router that provides your internet connection can detect your breathing through walls.</p>
<p>Ninety-nine techniques. Twenty-eight of them using hardware you already own — not health hardware, not smart hardware, just hardware with speakers and accelerometers and radios. Five of them chaining consumer sensors into escalation paths that terminate at brain-computer interfaces.</p>
<p>The map is public. The <a href="https://qinnovate.com/TARA">registry</a> is open. The point is not to make people afraid of their headphones. The point is to design the security before the ecosystem forms around the assumption that consumer sensors are benign.</p>
<p>They are not benign. They are dual-use. Just like every other technology in TARA.</p>
<h2 id="references">References</h2>
<ol>
<li>Michalevsky, Y., Boneh, D., &#x26; Nakibly, G. (2014). Gyrophone: Recognizing Speech from Gyroscope Signals. <em>USENIX Security Symposium</em>.</li>
<li>Guri, M., Solewicz, Y., Daidakulov, A., &#x26; Elovici, Y. (2017). SPEAKE(a)R: Turn Speakers to Microphones for Fun and Profit. <em>USENIX WOOT</em>.</li>
<li>Kaveh, A., et al. (2020). Wireless User Authentication in Ear-EEG. <em>IEEE Trans Biomed Eng</em>.</li>
<li>NEC Corporation (2016). Ear Acoustic Authentication Technology.</li>
<li>Muaaz, M. &#x26; Mayrhofer, R. (2017). Smartphone-Based Gait Recognition. <em>IEEE Trans Mobile Computing</em>.</li>
<li>Biswas, D., et al. (2019). CorNET: Deep Learning Framework for PPG-Based Biometric Identification. <em>IEEE Trans Biomed Eng</em>.</li>
<li>Becker, J., et al. (2022). Tracking Anonymized Bluetooth Devices. <em>PoPETS</em>.</li>
<li>Chen, W. &#x26; McDuff, D. (2018). DeepPhys: Video-Based Physiological Measurement. <em>ECCV</em>.</li>
<li>Zeng, Y., et al. (2020). FarSense: Pushing the Range Limit of WiFi-Based Respiration Sensing. <em>ACM MobiSys</em>.</li>
<li>Bot, B., et al. (2016). The mPower Study: Parkinson Disease Mobile Data. <em>Scientific Data</em>.</li>
<li>Katsini, C., et al. (2020). The Role of Eye Gaze in Security and Privacy Applications. <em>ACM Computing Surveys</em>.</li>
<li>Ba, Z., et al. (2020). Learning-based Practical Smartphone Eavesdropping with Built-in Accelerometer. <em>NDSS</em>.</li>
<li>Harrison, A. &#x26; Matyunin, N. (2023). A Practical Deep Learning-Based Acoustic Side Channel Attack on Keyboards. <em>IEEE EuroS&#x26;P Workshops</em>.</li>
<li>Zhao, M., et al. (2018). Through-Wall Human Pose Estimation Using Radio Signals. <em>CVPR</em>.</li>
<li>Arp, D., et al. (2017). Privacy Threats through Ultrasonic Side Channels on Mobile Devices. <em>IEEE EuroS&#x26;P</em>.</li>
<li>Yuste, R., et al. (2017). Four Ethical Priorities for Neurotechnologies and AI. <em>Nature</em> 551, 159-163.</li>
</ol>  </div> <!-- Article footer --> <footer class="mt-16 pt-8 border-t border-[var(--color-border)]"> <a href="/news/" class="text-sm text-[var(--color-accent-primary)] hover:text-[var(--color-accent-secondary)] transition-colors">
&larr; All news
</a> </footer> </article>  <script src="/js/derivation-timeline.js"></script> <footer class="border-t border-[var(--color-border)] mt-24 relative overflow-hidden" data-astro-cid-sz7xmlte> <!-- Background brand mark --> <div class="footer-brand-bg select-none pointer-events-none" aria-hidden="true" data-astro-cid-sz7xmlte> <span class="footer-brand font-bold font-[family-name:var(--font-heading)] leading-none bg-gradient-to-r from-[var(--color-accent-primary)] via-[var(--color-accent-secondary)] to-[var(--color-accent-tertiary)] bg-clip-text text-transparent" data-astro-cid-sz7xmlte>
QINNOVATE
</span> </div> <div class="relative z-10 max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-16" data-astro-cid-sz7xmlte> <div class="grid grid-cols-2 md:grid-cols-4 gap-8" data-astro-cid-sz7xmlte> <!-- Brand column --> <div class="col-span-2 md:col-span-1" data-astro-cid-sz7xmlte> <a href="/" class="text-xl font-bold font-[family-name:var(--font-heading)] text-[var(--color-text-primary)]" data-astro-cid-sz7xmlte>
Qinnovate Neural Alliance
</a> <p class="mt-3 text-sm text-[var(--color-text-muted)] leading-relaxed" data-astro-cid-sz7xmlte>
Introducing the heart of neurotechnology, starting governed by neuroethics and neurosecurity principles.
</p> <p class="mt-4 text-xs text-[var(--color-text-faint)]" data-astro-cid-sz7xmlte>
QIF v6.0 Hourglass &middot; Open Framework
</p> </div> <div data-astro-cid-sz7xmlte> <h3 class="text-sm font-semibold text-[var(--color-text-primary)] uppercase tracking-wider mb-4" data-astro-cid-sz7xmlte> Technology </h3> <ul class="space-y-3" data-astro-cid-sz7xmlte> <li data-astro-cid-sz7xmlte> <a href="/framework/" class="text-sm text-[var(--color-text-muted)] hover:text-[var(--color-accent-primary)] transition-colors" data-astro-cid-sz7xmlte> QIF Framework </a> </li><li data-astro-cid-sz7xmlte> <a href="/nsp/" class="text-sm text-[var(--color-text-muted)] hover:text-[var(--color-accent-primary)] transition-colors" data-astro-cid-sz7xmlte> NSP Protocol </a> </li><li data-astro-cid-sz7xmlte> <a href="/runemate/" class="text-sm text-[var(--color-text-muted)] hover:text-[var(--color-accent-primary)] transition-colors" data-astro-cid-sz7xmlte> Project Runemate </a> </li><li data-astro-cid-sz7xmlte> <a href="/TARA/" class="text-sm text-[var(--color-text-muted)] hover:text-[var(--color-accent-primary)] transition-colors" data-astro-cid-sz7xmlte> TARA Atlas </a> </li><li data-astro-cid-sz7xmlte> <a href="/scoring/" class="text-sm text-[var(--color-text-muted)] hover:text-[var(--color-accent-primary)] transition-colors" data-astro-cid-sz7xmlte> NISS Scoring </a> </li> </ul> </div><div data-astro-cid-sz7xmlte> <h3 class="text-sm font-semibold text-[var(--color-text-primary)] uppercase tracking-wider mb-4" data-astro-cid-sz7xmlte> Resources </h3> <ul class="space-y-3" data-astro-cid-sz7xmlte> <li data-astro-cid-sz7xmlte> <a href="/news/" class="text-sm text-[var(--color-text-muted)] hover:text-[var(--color-accent-primary)] transition-colors" data-astro-cid-sz7xmlte> News </a> </li><li data-astro-cid-sz7xmlte> <a href="/lab/" class="text-sm text-[var(--color-text-muted)] hover:text-[var(--color-accent-primary)] transition-colors" data-astro-cid-sz7xmlte> QIF Lab </a> </li><li data-astro-cid-sz7xmlte> <a href="/rss.xml" class="text-sm text-[var(--color-text-muted)] hover:text-[var(--color-accent-primary)] transition-colors" data-astro-cid-sz7xmlte> RSS Feed </a> </li> </ul> </div><div data-astro-cid-sz7xmlte> <h3 class="text-sm font-semibold text-[var(--color-text-primary)] uppercase tracking-wider mb-4" data-astro-cid-sz7xmlte> Connect </h3> <ul class="space-y-3" data-astro-cid-sz7xmlte> <li data-astro-cid-sz7xmlte> <a href="https://github.com/qinnovates" class="text-sm text-[var(--color-text-muted)] hover:text-[var(--color-accent-primary)] transition-colors" target="_blank" rel="noopener noreferrer" data-astro-cid-sz7xmlte> GitHub </a> </li><li data-astro-cid-sz7xmlte> <a href="https://medium.com/@qikevinl" class="text-sm text-[var(--color-text-muted)] hover:text-[var(--color-accent-primary)] transition-colors" target="_blank" rel="noopener noreferrer" data-astro-cid-sz7xmlte> Medium </a> </li><li data-astro-cid-sz7xmlte> <a href="/about/" class="text-sm text-[var(--color-text-muted)] hover:text-[var(--color-accent-primary)] transition-colors" data-astro-cid-sz7xmlte> About </a> </li><li data-astro-cid-sz7xmlte> <a href="/advisory/" class="text-sm text-[var(--color-text-muted)] hover:text-[var(--color-accent-primary)] transition-colors" data-astro-cid-sz7xmlte> Advisory </a> </li><li data-astro-cid-sz7xmlte> <a href="/licensing/" class="text-sm text-[var(--color-text-muted)] hover:text-[var(--color-accent-primary)] transition-colors" data-astro-cid-sz7xmlte> Licensing </a> </li> </ul> </div> </div> <div class="mt-12 pt-8 flex flex-col sm:flex-row justify-between items-center gap-4" data-astro-cid-sz7xmlte> <p class="text-xs text-[var(--color-text-faint)]" data-astro-cid-sz7xmlte>
&copy; 2026 Qinnovate Neural Alliance. QIF is an open research framework.
</p> </div> </div> </footer>   <!-- Scroll-driven reveal observer --> <script type="module">function o(){const t=new IntersectionObserver(e=>{e.forEach(r=>{r.isIntersecting&&(r.target.classList.add("revealed"),t.unobserve(r.target))})},{threshold:.1,rootMargin:"0px 0px -40px 0px"});document.querySelectorAll(".reveal").forEach(e=>t.observe(e))}o();document.addEventListener("astro:after-swap",o);</script> </body> </html>