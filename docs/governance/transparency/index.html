<!DOCTYPE html><html lang="en-US" data-theme="light"> <head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="description" content="Auditable record of Human-AI collaboration in QIF Framework development"><link rel="canonical" href="https://qinnovate.com/governance/transparency/"><!-- Favicon --><link rel="icon" type="image/svg+xml" href="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 100 100'%3E%3Ctext y='.9em' font-size='90' font-family='system-ui' fill='%2306b6d4'%3EQ%3C/text%3E%3C/svg%3E"><!-- Open Graph --><meta property="og:title" content="Transparency Statement"><meta property="og:description" content="Auditable record of Human-AI collaboration in QIF Framework development"><meta property="og:url" content="https://qinnovate.com/governance/transparency/"><meta property="og:site_name" content="Qinnovate"><meta property="og:type" content="website"><meta property="og:image" content="https://qinnovate.com/images/og-default.png"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="630"><meta property="og:locale" content="en_US"><!-- Twitter Card --><meta name="twitter:card" content="summary_large_image"><meta name="twitter:title" content="Transparency Statement"><meta name="twitter:description" content="Auditable record of Human-AI collaboration in QIF Framework development"><meta name="twitter:image" content="https://qinnovate.com/images/og-default.png"><meta name="twitter:creator" content="@qikevinl"><!-- JSON-LD Structured Data --><script type="application/ld+json">{"@context":"https://schema.org","@type":"Organization","name":"Qinnovate","url":"https://qinnovate.com","description":"Open standards and frameworks for brain-computer interface security.","foundingDate":"2026","sameAs":["https://github.com/qinnovates"]}</script><script type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Home","item":"https://qinnovate.com/"},{"@type":"ListItem","position":2,"name":"Governance","item":"https://qinnovate.com/governance/"},{"@type":"ListItem","position":3,"name":"Transparency Statement"}]}</script><!-- RSS autodiscovery --><link rel="alternate" type="application/rss+xml" title="Qinnovate Intel" href="/rss.xml"><title>Transparency Statement | Qinnovate</title><!-- View Transitions --><meta name="astro-view-transitions-enabled" content="true"><meta name="astro-view-transitions-fallback" content="animate"><script type="module" src="/_astro/ClientRouter.astro_astro_type_script_index_0_lang.CDGfc0hd.js"></script><!-- Google Analytics 4 --><script async src="https://www.googletagmanager.com/gtag/js?id=G-DKB9RWW0C2"></script><script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-DKB9RWW0C2');
  </script><!-- Theme initialization (prevent flash) --><script>
    (function(){ document.documentElement.setAttribute('data-theme', 'light'); })();
  </script><link rel="stylesheet" href="/_astro/TARA.w5QsKvtK.css">
<link rel="stylesheet" href="/_astro/TARA.C_iNMcSg.css"></head> <body class="min-h-screen">  <nav class="glass fixed top-0 left-0 right-0 z-50 border-b border-[var(--color-border)]" id="main-nav" data-astro-transition-persist="astro-zscz5gm2-1"> <div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8"> <div class="flex items-center justify-between h-16"> <!-- Logo --> <a href="/" class="flex items-center gap-2 hover:opacity-80 transition-opacity"> <span class="text-2xl font-bold font-[family-name:var(--font-heading)] bg-gradient-to-r from-[var(--color-accent-primary)] via-[var(--color-accent-secondary)] to-[var(--color-accent-tertiary)] bg-clip-text text-transparent">Q</span> <span class="text-sm font-medium tracking-wider uppercase hidden sm:inline text-[var(--color-text-primary)]">innovate</span> </a> <!-- Desktop links --> <div class="hidden md:flex items-center gap-1"> <!-- About (flat link) --> <a href="/about/" class="px-3 py-2 rounded-lg text-sm font-medium transition-colors text-[var(--color-text-muted)] hover:text-[var(--color-text-primary)] hover:bg-black/5">
About
</a> <!-- Technology dropdown --> <div class="relative" data-dropdown="tech"> <button class="flex items-center gap-1 px-3 py-2 rounded-lg text-sm font-medium transition-colors text-[var(--color-text-muted)] hover:text-[var(--color-text-primary)] hover:bg-black/5">
Technology
<svg class="w-3.5 h-3.5 opacity-60" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2"> <path stroke-linecap="round" stroke-linejoin="round" d="M19.5 8.25l-7.5 7.5-7.5-7.5"></path> </svg> </button> <div class="dropdown-menu absolute left-0 top-full pt-2 hidden"> <div class="glass rounded-xl border border-[var(--color-border)] shadow-xl w-72 overflow-hidden"> <div class="p-2"> <a href="/framework/" class="block px-3 py-2.5 rounded-lg transition-colors text-[var(--color-text-muted)] hover:text-[var(--color-text-primary)] hover:bg-black/5"> <span class="text-sm font-medium block leading-snug">QIF Framework</span> <span class="text-xs text-[var(--color-text-faint)] block mt-0.5 leading-snug">The 11-band hourglass governance architecture</span> </a><a href="/nsp/" class="block px-3 py-2.5 rounded-lg transition-colors text-[var(--color-text-muted)] hover:text-[var(--color-text-primary)] hover:bg-black/5"> <span class="text-sm font-medium block leading-snug">NSP Protocol</span> <span class="text-xs text-[var(--color-text-faint)] block mt-0.5 leading-snug">Secure communication protocol for patient safety and privacy</span> </a><a href="/runemate/" class="block px-3 py-2.5 rounded-lg transition-colors text-[var(--color-text-muted)] hover:text-[var(--color-text-primary)] hover:bg-black/5"> <span class="text-sm font-medium block leading-snug">Runemate</span> <span class="text-xs text-[var(--color-text-faint)] block mt-0.5 leading-snug">Compiler enabling on-device security for neural implants</span> </a><a href="/TARA/" class="block px-3 py-2.5 rounded-lg transition-colors text-[var(--color-text-muted)] hover:text-[var(--color-text-primary)] hover:bg-black/5"> <span class="text-sm font-medium block leading-snug">TARA</span> <span class="text-xs text-[var(--color-text-faint)] block mt-0.5 leading-snug">Risk taxonomy — attacks, ethical risks, and therapeutic applications</span> </a><a href="/whitepaper/" class="block px-3 py-2.5 rounded-lg transition-colors text-[var(--color-text-muted)] hover:text-[var(--color-text-primary)] hover:bg-black/5"> <span class="text-sm font-medium block leading-snug">Whitepaper</span> <span class="text-xs text-[var(--color-text-faint)] block mt-0.5 leading-snug">Full QIF specification document</span> </a> </div> </div> </div> </div> <!-- Resources dropdown --> <div class="relative" data-dropdown="resources"> <button class="flex items-center gap-1 px-3 py-2 rounded-lg text-sm font-medium transition-colors text-[var(--color-text-muted)] hover:text-[var(--color-text-primary)] hover:bg-black/5">
Resources
<svg class="w-3.5 h-3.5 opacity-60" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2"> <path stroke-linecap="round" stroke-linejoin="round" d="M19.5 8.25l-7.5 7.5-7.5-7.5"></path> </svg> </button> <div class="dropdown-menu absolute left-0 top-full pt-2 hidden"> <div class="glass rounded-xl border border-[var(--color-border)] shadow-xl w-64 overflow-hidden"> <div class="p-2"> <a href="/news/" class="block px-3 py-2.5 rounded-lg transition-colors text-[var(--color-text-muted)] hover:text-[var(--color-text-primary)] hover:bg-black/5"> <span class="text-sm font-medium block leading-snug">News</span> <span class="text-xs text-[var(--color-text-faint)] block mt-0.5 leading-snug">Latest publications and updates</span> </a><a href="/explore/" class="block px-3 py-2.5 rounded-lg transition-colors text-[var(--color-text-muted)] hover:text-[var(--color-text-primary)] hover:bg-black/5"> <span class="text-sm font-medium block leading-snug">Explore</span> <span class="text-xs text-[var(--color-text-faint)] block mt-0.5 leading-snug">Interactive visualizations and tools</span> </a><a href="/glossary/" class="block px-3 py-2.5 rounded-lg transition-colors text-[var(--color-text-muted)] hover:text-[var(--color-text-primary)] hover:bg-black/5"> <span class="text-sm font-medium block leading-snug">Glossary</span> <span class="text-xs text-[var(--color-text-faint)] block mt-0.5 leading-snug">QIF terminology reference</span> </a> </div> </div> </div> </div> <!-- Engage dropdown --> <div class="relative" data-dropdown="engage"> <button class="flex items-center gap-1 px-3 py-2 rounded-lg text-sm font-medium transition-colors text-[var(--color-text-muted)] hover:text-[var(--color-text-primary)] hover:bg-black/5">
Engage
<svg class="w-3.5 h-3.5 opacity-60" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2"> <path stroke-linecap="round" stroke-linejoin="round" d="M19.5 8.25l-7.5 7.5-7.5-7.5"></path> </svg> </button> <div class="dropdown-menu absolute left-0 top-full pt-2 hidden"> <div class="glass rounded-xl border border-[var(--color-border)] shadow-xl w-72 overflow-hidden"> <div class="p-2"> <a href="/adopt/" class="block px-3 py-2.5 rounded-lg transition-colors text-[var(--color-text-muted)] hover:text-[var(--color-text-primary)] hover:bg-black/5"> <span class="text-sm font-medium block leading-snug">Adopt the Standard</span> <span class="text-xs text-[var(--color-text-faint)] block mt-0.5 leading-snug">Integrate QIF into your organization or research</span> </a><a href="/advisory/" class="block px-3 py-2.5 rounded-lg transition-colors text-[var(--color-text-muted)] hover:text-[var(--color-text-primary)] hover:bg-black/5"> <span class="text-sm font-medium block leading-snug">Advisory Services</span> <span class="text-xs text-[var(--color-text-faint)] block mt-0.5 leading-snug">Hands-on guidance for BCI security implementation</span> </a><a href="https://github.com/qinnovates/qinnovate" target="_blank" rel="noopener noreferrer" class="block px-3 py-2.5 rounded-lg transition-colors text-[var(--color-text-muted)] hover:text-[var(--color-text-primary)] hover:bg-black/5"> <span class="text-sm font-medium block leading-snug">Get Involved</span> <span class="text-xs text-[var(--color-text-faint)] block mt-0.5 leading-snug">Contribute on GitHub — issues, PRs, discussions</span> </a> </div> </div> </div> </div> <!-- Governance dropdown --> <div class="relative" data-dropdown="gov"> <a href="/governance/" class="flex items-center gap-1 px-3 py-2 rounded-lg text-sm font-medium transition-colors text-[var(--color-accent-primary)] bg-[var(--color-accent-primary)]/10">
Governance
<svg class="w-3.5 h-3.5 opacity-60" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2"> <path stroke-linecap="round" stroke-linejoin="round" d="M19.5 8.25l-7.5 7.5-7.5-7.5"></path> </svg> </a> <div class="dropdown-menu absolute right-0 top-full pt-2 hidden"> <div class="glass rounded-xl border border-[var(--color-border)] shadow-xl w-72 overflow-hidden"> <div class="p-2"> <a href="/governance/#core" class="block px-3 py-2.5 rounded-lg transition-colors text-[var(--color-text-muted)] hover:text-[var(--color-text-primary)] hover:bg-black/5"> <span class="text-sm font-medium block leading-snug">Core Standards</span> <span class="text-xs text-[var(--color-text-faint)] block mt-0.5 leading-snug">Code of Conduct, Transparency, Data Policy, Accessibility</span> </a><a href="/governance/#ethics" class="block px-3 py-2.5 rounded-lg transition-colors text-[var(--color-text-muted)] hover:text-[var(--color-text-primary)] hover:bg-black/5"> <span class="text-sm font-medium block leading-snug">Ethics &amp; Rights</span> <span class="text-xs text-[var(--color-text-faint)] block mt-0.5 leading-snug">Neuroethics, Informed Consent, Pediatric, Post-Deployment</span> </a><a href="/governance/#compliance" class="block px-3 py-2.5 rounded-lg transition-colors text-[var(--color-text-muted)] hover:text-[var(--color-text-primary)] hover:bg-black/5"> <span class="text-sm font-medium block leading-snug">Compliance</span> <span class="text-xs text-[var(--color-text-faint)] block mt-0.5 leading-snug">Regulatory, UNESCO Alignment, QIF Neuroethics</span> </a> </div> </div> </div> </div> </div> <!-- Right side --> <div class="flex items-center gap-3"> <!-- GitHub link --> <a href="https://github.com/qinnovates/qinnovate" target="_blank" rel="noopener noreferrer" class="p-2 rounded-lg text-[var(--color-text-muted)] hover:text-[var(--color-text-primary)] hover:bg-black/5 transition-colors" aria-label="GitHub"> <svg class="w-5 h-5" fill="currentColor" viewBox="0 0 24 24"> <path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"></path> </svg> </a> <!-- Search button --> <button id="search-btn" class="p-2 rounded-lg text-[var(--color-text-muted)] hover:text-[var(--color-text-primary)] hover:bg-black/5 transition-colors" aria-label="Search"> <svg class="w-5 h-5" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2"> <path stroke-linecap="round" stroke-linejoin="round" d="M21 21l-5.197-5.197m0 0A7.5 7.5 0 105.196 5.196a7.5 7.5 0 0010.607 10.607z"></path> </svg> </button> <!-- Mobile menu button --> <button id="mobile-menu-btn" class="md:hidden p-2 rounded-lg text-[var(--color-text-muted)] hover:text-[var(--color-text-primary)] hover:bg-black/5 transition-colors" aria-label="Open menu" aria-expanded="false"> <svg class="w-5 h-5" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2"> <path stroke-linecap="round" stroke-linejoin="round" d="M4 6h16M4 12h16M4 18h16"></path> </svg> </button> </div> </div> </div> <!-- Mobile menu --> <div id="mobile-menu" class="md:hidden hidden border-t border-[var(--color-border)]"> <div class="px-4 py-3 space-y-1"> <!-- About (flat) --> <a href="/about/" class="block px-3 py-2 rounded-lg text-sm font-medium transition-colors text-[var(--color-text-muted)] hover:text-[var(--color-text-primary)] hover:bg-black/5">
About
</a> <!-- Mobile Technology section --> <div> <button data-mobile-toggle="tech" class="flex items-center justify-between w-full px-3 py-2 rounded-lg text-sm font-medium transition-colors text-[var(--color-text-muted)] hover:text-[var(--color-text-primary)] hover:bg-black/5">
Technology
<svg class="w-3.5 h-3.5 opacity-60 transition-transform" data-chevron="tech" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2"> <path stroke-linecap="round" stroke-linejoin="round" d="M19.5 8.25l-7.5 7.5-7.5-7.5"></path> </svg> </button> <div data-mobile-list="tech" class="hidden pl-3 space-y-0.5 mt-1"> <a href="/framework/" class="block px-3 py-1.5 rounded-lg text-sm transition-colors text-[var(--color-text-faint)] hover:text-[var(--color-text-primary)]"> QIF Framework </a><a href="/nsp/" class="block px-3 py-1.5 rounded-lg text-sm transition-colors text-[var(--color-text-faint)] hover:text-[var(--color-text-primary)]"> NSP Protocol </a><a href="/runemate/" class="block px-3 py-1.5 rounded-lg text-sm transition-colors text-[var(--color-text-faint)] hover:text-[var(--color-text-primary)]"> Runemate </a><a href="/TARA/" class="block px-3 py-1.5 rounded-lg text-sm transition-colors text-[var(--color-text-faint)] hover:text-[var(--color-text-primary)]"> TARA </a><a href="/whitepaper/" class="block px-3 py-1.5 rounded-lg text-sm transition-colors text-[var(--color-text-faint)] hover:text-[var(--color-text-primary)]"> Whitepaper </a> </div> </div> <!-- Mobile Resources section --> <div> <button data-mobile-toggle="resources" class="flex items-center justify-between w-full px-3 py-2 rounded-lg text-sm font-medium transition-colors text-[var(--color-text-muted)] hover:text-[var(--color-text-primary)] hover:bg-black/5">
Resources
<svg class="w-3.5 h-3.5 opacity-60 transition-transform" data-chevron="resources" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2"> <path stroke-linecap="round" stroke-linejoin="round" d="M19.5 8.25l-7.5 7.5-7.5-7.5"></path> </svg> </button> <div data-mobile-list="resources" class="hidden pl-3 space-y-0.5 mt-1"> <a href="/news/" class="block px-3 py-1.5 rounded-lg text-sm transition-colors text-[var(--color-text-faint)] hover:text-[var(--color-text-primary)]"> News </a><a href="/explore/" class="block px-3 py-1.5 rounded-lg text-sm transition-colors text-[var(--color-text-faint)] hover:text-[var(--color-text-primary)]"> Explore </a><a href="/glossary/" class="block px-3 py-1.5 rounded-lg text-sm transition-colors text-[var(--color-text-faint)] hover:text-[var(--color-text-primary)]"> Glossary </a> </div> </div> <!-- Mobile Engage section --> <div> <button data-mobile-toggle="engage" class="flex items-center justify-between w-full px-3 py-2 rounded-lg text-sm font-medium transition-colors text-[var(--color-text-muted)] hover:text-[var(--color-text-primary)] hover:bg-black/5">
Engage
<svg class="w-3.5 h-3.5 opacity-60 transition-transform" data-chevron="engage" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2"> <path stroke-linecap="round" stroke-linejoin="round" d="M19.5 8.25l-7.5 7.5-7.5-7.5"></path> </svg> </button> <div data-mobile-list="engage" class="hidden pl-3 space-y-0.5 mt-1"> <a href="/adopt/" class="block px-3 py-1.5 rounded-lg text-sm transition-colors text-[var(--color-text-faint)] hover:text-[var(--color-text-primary)]"> Adopt the Standard </a><a href="/advisory/" class="block px-3 py-1.5 rounded-lg text-sm transition-colors text-[var(--color-text-faint)] hover:text-[var(--color-text-primary)]"> Advisory Services </a><a href="https://github.com/qinnovates/qinnovate" target="_blank" rel="noopener noreferrer" class="block px-3 py-1.5 rounded-lg text-sm transition-colors text-[var(--color-text-faint)] hover:text-[var(--color-text-primary)]"> Get Involved </a> </div> </div> <!-- Mobile Governance section --> <div class="pt-2 border-t border-[var(--color-border)] mt-2"> <button data-mobile-toggle="gov" class="flex items-center justify-between w-full px-3 py-2 rounded-lg text-sm font-medium transition-colors text-[var(--color-accent-primary)] bg-[var(--color-accent-primary)]/10">
Governance
<svg class="w-3.5 h-3.5 opacity-60 transition-transform" data-chevron="gov" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2"> <path stroke-linecap="round" stroke-linejoin="round" d="M19.5 8.25l-7.5 7.5-7.5-7.5"></path> </svg> </button> <div data-mobile-list="gov" class="hidden pl-3 space-y-0.5 mt-1"> <a href="/governance/#core" class="block px-3 py-1.5 rounded-lg text-sm transition-colors text-[var(--color-text-faint)] hover:text-[var(--color-text-primary)]"> Core Standards </a><a href="/governance/#ethics" class="block px-3 py-1.5 rounded-lg text-sm transition-colors text-[var(--color-text-faint)] hover:text-[var(--color-text-primary)]"> Ethics &amp; Rights </a><a href="/governance/#compliance" class="block px-3 py-1.5 rounded-lg text-sm transition-colors text-[var(--color-text-faint)] hover:text-[var(--color-text-primary)]"> Compliance </a> </div> </div> </div> </div> </nav> <!-- Search modal --> <div id="search-modal" class="fixed inset-0 z-[100] hidden"> <div id="search-backdrop" class="absolute inset-0 bg-black/60 backdrop-blur-sm"></div> <div class="relative max-w-2xl mx-auto mt-20 px-4"> <div class="glass rounded-xl p-4 shadow-2xl" id="search-container"> <div id="search" class="pagefind-ui pagefind-init" data-pagefind-ui data-bundle-path="/pagefind/" data-ui-options="{&#34;showImages&#34;:false,&#34;showSubResults&#34;:true}"></div> <script type="module" src="/_astro/Search.astro_astro_type_script_index_0_lang.tZYucdM2.js"></script> </div> </div> </div> <script type="module">function u(){const n=document.getElementById("mobile-menu-btn"),i=document.getElementById("mobile-menu");n?.addEventListener("click",()=>{const e=n.getAttribute("aria-expanded")==="true";n.setAttribute("aria-expanded",String(!e)),i?.classList.toggle("hidden")}),document.addEventListener("astro:before-swap",()=>{i?.classList.add("hidden"),n?.setAttribute("aria-expanded","false")}),document.querySelectorAll("[data-dropdown]").forEach(e=>{const t=e.querySelector(".dropdown-menu");let a;function c(){document.querySelectorAll(".dropdown-menu").forEach(o=>{o!==t&&o.classList.add("hidden")}),clearTimeout(a),t?.classList.remove("hidden")}function l(){a=setTimeout(()=>{t?.classList.add("hidden")},150)}e.addEventListener("mouseenter",c),e.addEventListener("mouseleave",l),e.addEventListener("focusin",c),e.addEventListener("focusout",o=>{e.contains(o.relatedTarget)||l()})}),document.querySelectorAll("[data-mobile-toggle]").forEach(e=>{const t=e.getAttribute("data-mobile-toggle"),a=document.querySelector(`[data-mobile-list="${t}"]`),c=document.querySelector(`[data-chevron="${t}"]`);e.addEventListener("click",()=>{a?.classList.toggle("hidden"),c?.classList.toggle("rotate-180")})});const m=document.getElementById("search-btn"),d=document.getElementById("search-modal"),h=document.getElementById("search-backdrop");function r(){d?.classList.remove("hidden"),setTimeout(()=>{d?.querySelector(".pagefind-ui__search-input")?.focus()},50)}function s(){d?.classList.add("hidden")}m?.addEventListener("click",r),h?.addEventListener("click",s),document.addEventListener("keydown",e=>{(e.metaKey||e.ctrlKey)&&e.key==="k"&&(e.preventDefault(),d?.classList.contains("hidden")?r():s()),e.key==="Escape"&&s()}),document.addEventListener("astro:before-swap",s)}u();document.addEventListener("astro:after-swap",u);</script> <article class="max-w-4xl mx-auto px-4 sm:px-6 lg:px-8 pt-24 pb-16"> <nav aria-label="Breadcrumb" class="text-sm text-[var(--color-text-faint)] mb-6"> <ol class="flex items-center gap-2 flex-wrap"> <li> <a href="/" class="hover:text-[var(--color-accent-primary)] transition-colors">Home</a> </li>  <li aria-hidden="true" class="select-none">/</li> <li> <a href="/governance/" class="hover:text-[var(--color-accent-primary)] transition-colors"> Governance </a> </li>  <li aria-hidden="true" class="select-none">/</li> <li> <span class="text-[var(--color-text-muted)]">Transparency Statement</span> </li>  </ol> </nav> <header class="mb-12"> <h1 class="text-3xl sm:text-4xl font-bold font-[family-name:var(--font-heading)] leading-tight mb-4"> Transparency Statement </h1> <p class="text-lg text-[var(--color-text-muted)] italic">Auditable record of Human-AI collaboration in QIF Framework development</p> </header> <div class="prose"> <h1 id="transparency-statement-human-ai-collaboration-in-qif-framework">Transparency Statement: Human-AI Collaboration in QIF Framework</h1>
<blockquote>
<p>This document serves as an auditable record of how AI tools were integrated into the development of the QIF (Quantum Indeterministic Framework for Neural Security), demonstrating principles of Responsible AI, cognitive boundary maintenance, and Human-in-the-Loop (HITL) methodology.</p>
</blockquote>
<p><strong>Last Updated:</strong> 2026-02-03
<strong>Document Version:</strong> 2.0
<strong>Detailed Derivation Timeline:</strong> <a href="../../../drafts/ai-working/QIF-DERIVATION-LOG.md"><code>QIF-DERIVATION-LOG.md</code></a> — Complete chronological record of every derivation, decision, AI contribution, and validation result with timestamps and reasoning chains.</p>
<hr>
<h2 id="purpose">Purpose</h2>
<p>The QIF Framework addresses security for brain-computer interfaces—technology that will fundamentally alter the human-machine boundary. It is therefore essential that the <em>development process itself</em> models the transparency and cognitive autonomy principles the framework seeks to protect.</p>
<p>This document:</p>
<ol>
<li>Defines the cognitive boundary between human and AI contributions</li>
<li>Documents the Human-in-the-Loop refinement process</li>
<li>Provides an auditable trail for academic and professional review</li>
<li>Serves as a case study in Responsible AI methodology</li>
</ol>
<h3 id="where-to-find-what">Where to Find What</h3>

























<table><thead><tr><th>Document</th><th>What It Contains</th></tr></thead><tbody><tr><td><strong>This file (TRANSPARENCY.md)</strong></td><td>Collaboration methodology, contribution matrix, correction examples, tool disclosure</td></tr><tr><td><strong><a href="../../../drafts/ai-working/QIF-DERIVATION-LOG.md">QIF-DERIVATION-LOG.md</a></strong></td><td>Complete timestamped timeline of every derivation, insight, AI contribution, validation result, and decision — from project inception (2026-01-18) to present. <strong>Start here for the full audit trail.</strong></td></tr><tr><td><strong><a href="../../../drafts/ai-working/QIF-RESEARCH-SOURCES.md">QIF-RESEARCH-SOURCES.md</a></strong></td><td>All 102+ research sources compiled during AI-assisted validation sessions, with attribution to which agent/tool found each source</td></tr><tr><td><strong><a href="../../../drafts/ai-working/PROPAGATION.md">PROPAGATION.md</a></strong></td><td>Validation pipeline: when and how independent review (including cross-AI review) is triggered</td></tr></tbody></table>
<hr>
<h2 id="methodology-the-cognitive-division">Methodology: The Cognitive Division</h2>
<h3 id="core-principle">Core Principle</h3>
<p>Every contribution is categorized by its cognitive origin. AI assistance is treated as a tool subject to human oversight, not a collaborator with independent judgment on ethical or novel technical matters.</p>
<h3 id="contribution-matrix">Contribution Matrix</h3>

































































<table><thead><tr><th>Domain</th><th>Human Contribution</th><th>AI Contribution</th><th>Boundary Notes</th></tr></thead><tbody><tr><td><strong>Conceptual Architecture</strong></td><td>14-layer model concept, OSI-mirrored 7-layer silicon side, attack surface identification, layer-to-ethics mapping</td><td>Co-mapping of biological layers (nervous system analogs for L9-L14)</td><td>Human conceived the dual-stack structure and knew 7 silicon layers were required (mirroring OSI); AI assisted in mapping the biological nervous system layers</td></tr><tr><td><strong>v3.0/v3.1 Hourglass Architecture</strong></td><td>All 6 architectural decisions (7-band, 3-1-3 symmetry, N3 rename, amygdala split, cerebellum spanning, QI range philosophy), rejection of N4 band</td><td>Co-derivation of hourglass geometry (Entries 1-13), research agent validation (102 sources), implementation across codebase</td><td>Human made all final decisions; AI proposed options and implemented choices. See Derivation Log Entries 14-15.</td></tr><tr><td><strong>Mathematical Formulas</strong></td><td>Cₛ coherence metric conception, variable selection (σ²φ, σ²τ, σ²γ), security interpretations</td><td>LaTeX formatting, notation consistency</td><td>Human selected which variances matter for security; AI formatted</td></tr><tr><td><strong>Security Decisions</strong></td><td>Zero-trust architecture choice, firewall placement at L8, rejection thresholds</td><td>None</td><td>All security-critical decisions made by human judgment</td></tr><tr><td><strong>Quantum Security Concepts</strong></td><td>TTT as security primitive, QPUF authentication proposal, liminal phase hypothesis</td><td>Literature organization</td><td>Novel security applications are human contributions</td></tr><tr><td><strong>Code Implementation</strong></td><td>Algorithm design, API decisions, security-critical logic</td><td>Syntax generation, boilerplate, docstrings</td><td>Human reviewed all generated code for security implications</td></tr><tr><td><strong>Research Synthesis</strong></td><td>Source selection, relevance judgment, argument construction, conclusions</td><td>Initial literature summaries (Claude), independent validation and critique (Gemini)</td><td>All AI summaries verified against primary sources; Gemini served as independent reviewer to counter single-model bias</td></tr><tr><td><strong>Technical Writing</strong></td><td>All original analysis, ethical arguments, novel hypotheses</td><td>Structural suggestions, grammar, APA formatting</td><td>Human wrote arguments; AI assisted with presentation</td></tr><tr><td><strong>Blog Posts</strong></td><td>Core narratives, analogies, original insights</td><td>Draft structuring, SEO optimization</td><td>Human voice and perspective preserved throughout</td></tr></tbody></table>
<hr>
<h2 id="the-refinement-loop-human-in-the-loop-evidence">The Refinement Loop: Human-in-the-Loop Evidence</h2>
<h3 id="documented-corrections">Documented Corrections</h3>
<p>The following examples demonstrate active human oversight correcting AI output:</p>
<h4 id="example-1-quantum-coherence-timescales">Example 1: Quantum Coherence Timescales</h4>
<ul>
<li><strong>AI Initial Output</strong>: Suggested biological quantum coherence persists for ~10 milliseconds</li>
<li><strong>Human Correction</strong>: Rejected; actual biological coherence timescales are ~100 femtoseconds (Engel et al., 2007)</li>
<li><strong>Action Taken</strong>: Corrected in TechDoc-Quantum_Encryption.md with proper citation</li>
<li><strong>Lesson</strong>: AI hallucinated a plausible-sounding but incorrect value by three orders of magnitude</li>
</ul>
<h4 id="example-2-encryption-architecture">Example 2: Encryption Architecture</h4>
<ul>
<li><strong>AI Initial Output</strong>: Suggested symmetric encryption for neural signal authentication</li>
<li><strong>Human Override</strong>: Rejected due to key distribution vulnerability in implanted devices</li>
<li><strong>Action Taken</strong>: Pivoted to QPUF-based authentication as documented in quantum-encryption publications</li>
<li><strong>Ethical Reasoning</strong>: Key distribution in BCIs creates attack surface for “harvest now, decrypt later” scenarios affecting long-term cognitive autonomy</li>
</ul>
<h4 id="example-3-transport-variance-defaults">Example 3: Transport Variance Defaults</h4>
<ul>
<li><strong>AI Initial Output</strong>: Suggested using uniform reliability factors (all 0.95)</li>
<li><strong>Human Override</strong>: Rejected; biological pathways have heterogeneous reliability</li>
<li><strong>Action Taken</strong>: Researched actual synaptic transmission reliability (~0.85), myelination effects, etc.</li>
<li><strong>Lesson</strong>: AI defaulted to simplified assumptions that would reduce biological validity</li>
</ul>
<p><strong>Expanded Analysis — Why Synaptic Reliability Dominates:</strong></p>
<p>The Coherence Metric (Cₛ) combines three variance components: phase (σ²φ), transport (σ²τ), and gain (σ²γ). Understanding <em>why</em> transport variance dominates required multiple iterations:</p>
<ol>
<li>
<p><strong>Biological Reality of Synaptic Transmission</strong>: Synaptic vesicle release is inherently probabilistic — approximately 85% reliable per synapse (Branco &#x26; Bhalla, 2006; Del Castillo &#x26; Katz, 1954). This isn’t a defect; it’s a feature enabling neural plasticity and energy efficiency.</p>
</li>
<li>
<p><strong>Compounding Effect Across Pathways</strong>: Neural signals traverse multi-synaptic pathways. For a 3-synapse pathway: 0.85³ ≈ 0.61 reliability. For 5 synapses: 0.85⁵ ≈ 0.44. This exponential degradation means transport variance accumulates faster than phase or gain variance.</p>
</li>
<li>
<p><strong>Why This Matters for Security</strong>: An attacker cannot easily <em>improve</em> transport reliability — it’s biologically constrained. However, they can <em>exploit</em> it by injecting signals that appear to have unnaturally high reliability (>0.95), which should trigger anomaly detection. Signals with <em>too perfect</em> transmission are as suspicious as degraded ones.</p>
</li>
<li>
<p><strong>The Learning Moment</strong>: AI’s suggestion of uniform 0.95 reliability would have:</p>
<ul>
<li>
<p><strong>Overestimated baseline signal quality</strong>: A 0.95 reliability assumption is 10 percentage points higher than biological reality (~0.85). This might seem like a small difference, but compounded across pathways it dramatically shifts expectations. At 0.95³ = 0.86 reliability for 3 synapses vs. 0.85³ = 0.61 — the AI’s assumption would predict 40% higher pathway reliability than actually exists. Any coherence threshold calibrated on these inflated baselines would be fundamentally miscalibrated.</p>
</li>
<li>
<p><strong>Missed a key attack detection vector (supranormal reliability)</strong>: “Supranormal” means <em>above the normal biological range</em>. If real synapses transmit at ~85% reliability, a signal showing 95%+ reliability is biologically implausible — it’s <em>too clean</em>. This is a critical security insight: attackers injecting synthetic signals into a BCI cannot easily replicate the natural “messiness” of biological transmission. Their signals will be suspiciously reliable. By using 0.95 as our baseline, we would have normalized this attack signature, making it invisible to detection. The 0.95 threshold matters specifically because it sits at the boundary of biological plausibility — signals above this should trigger immediate scrutiny.</p>
</li>
<li>
<p><strong>Ignored decades of neuroscience research on synaptic stochasticity</strong>: The probabilistic nature of synaptic transmission has been documented since Katz’s Nobel Prize-winning work in the 1950s-70s (Del Castillo &#x26; Katz, 1954). This isn’t obscure knowledge — it’s foundational neuroscience. The AI’s “clean” assumption of 0.95 revealed a pattern: AI systems optimize for mathematical elegance (uniform, high values) rather than biological fidelity (heterogeneous, lower values). This is precisely the kind of domain-specific knowledge that requires human oversight.</p>
</li>
</ul>
<p><strong>Why 0.95 Specifically?</strong> The AI likely selected 0.95 because it’s a common “high confidence” placeholder in engineering contexts (like 95% confidence intervals). But this reveals a category error: applying statistical conventions to biological systems. Real synapses don’t care about human statistical preferences — they evolved under constraints of energy efficiency, plasticity, and noise tolerance that produce ~85% reliability as an <em>optimal</em> tradeoff, not a limitation.</p>
</li>
</ol>
<p>This example illustrates why domain expertise cannot be fully offloaded to AI — the AI optimized for “clean” assumptions while biological systems operate on “messy” realities that carry security-relevant information. The mess <em>is</em> the signal.</p>
<h4 id="example-4-firewall-decision-matrix">Example 4: Firewall Decision Matrix</h4>
<ul>
<li><strong>AI Initial Output</strong>: Suggested binary accept/reject based solely on coherence score</li>
<li><strong>Human Enhancement</strong>: Added authentication requirement and ACCEPT_FLAG intermediate state</li>
<li><strong>Reasoning</strong>: Zero-trust principles require identity verification independent of signal quality</li>
<li><strong>Action Taken</strong>: Implemented full decision matrix with alert levels</li>
</ul>
<h4 id="example-5-coherence-formula-notation-correction-2026-01-26">Example 5: Coherence Formula Notation Correction (2026-01-26)</h4>
<ul>
<li><strong>Legacy Notation</strong>: <code>Cₛ = Σᵢ wᵢ × Φᵢ(Δtᵢ) × Θᵢ(fᵢ, Aᵢ)</code> (weighted sum representation)</li>
<li><strong>Authoritative Formula</strong>: <code>Cₛ = e^(−(σ²φ + σ²τ + σ²γ))</code> (exponential decay)</li>
<li><strong>Discovery Process</strong>: Systematic repository audit found 8 files containing the legacy notation that contradicted the authoritative TechDoc and code implementation</li>
<li><strong>Mathematical Proof</strong>:
<ol>
<li>The exponential form models biological threshold behaviors (Markram et al., 1997 — STDP windows)</li>
<li>Formula is derived from Shannon entropy: Cₛ = e^(−H_total) where H_total = total variance</li>
<li>Produces bounded output [0, 1] with proper asymptotic behavior (Cₛ → 1 as variance → 0)</li>
<li>All 14 unit tests in <code>test_coherence.py</code> explicitly verify e^−x behavior</li>
<li>Both <code>oni-framework</code> and <code>tara_mvp</code> implementations use <code>math.exp(-total_variance)</code></li>
</ol>
</li>
<li><strong>Files Corrected</strong>: CLAUDE.md, AGENTS.md, TARA/API.md, TARA/CLAUDE.md, PERSONAS.md, app.py, CoherenceGauge.tsx, coherence.tsx</li>
<li><strong>Lesson</strong>: Legacy notation from early development propagated to auxiliary documentation without review against authoritative sources. This underscores the importance of establishing clear truth hierarchies (TechDoc > Implementation > Supporting docs).</li>
</ul>
<h3 id="correction-rate">Correction Rate</h3>
<p>Across the development of ONI Framework v0.1.0:</p>
<ul>
<li><strong>Total AI suggestions reviewed</strong>: ~200+</li>
<li><strong>Accepted without modification</strong>: ~60%</li>
<li><strong>Accepted with modification</strong>: ~25%</li>
<li><strong>Rejected entirely</strong>: ~15%</li>
</ul>
<p>The 40% modification/rejection rate demonstrates active critical engagement, not passive acceptance.</p>
<hr>
<h2 id="verification-protocol">Verification Protocol</h2>
<h3 id="scientific-claims">Scientific Claims</h3>
<ul>
<li>All neuroscience claims verified against peer-reviewed sources</li>
<li>Quantum physics claims cross-referenced with recent experimental literature</li>
<li>Biological assumptions explicitly flagged for expert review (see ../CONTRIBUTING.md)</li>
</ul>
<h3 id="code-quality">Code Quality</h3>
<ul>
<li>77 unit tests covering all core modules</li>
<li>No AI-generated tests accepted without manual review and modification</li>
<li>Security-critical code paths manually audited</li>
</ul>
<h3 id="documentation">Documentation</h3>
<ul>
<li>All “facts” in technical documents traced to citations</li>
<li>Speculative content clearly marked as hypotheses</li>
<li>Research status disclaimer prominent in README and package documentation</li>
</ul>
<hr>
<h2 id="cognitive-boundary-maintenance">Cognitive Boundary Maintenance</h2>
<h3 id="the-challenge">The Challenge</h3>
<p>Using AI for efficiency creates a risk: cognitive offloading may trade deep understanding for breadth. This tension is directly relevant to neuroethics, where we ask similar questions about neural augmentation.</p>
<h3 id="self-assessment">Self-Assessment</h3>
<p><strong>Where AI Helped Understanding:</strong></p>
<ul>
<li>Rapid literature survey revealed connections I might have missed</li>
<li>Forcing clear documentation improved my own conceptual clarity</li>
<li>Debugging conversations exposed gaps in my reasoning</li>
</ul>
<p><strong>Where AI Hindered Understanding:</strong></p>
<ul>
<li>Initial over-reliance on AI-structured outlines delayed developing my own organizational logic</li>
<li>Transport variance defaults required multiple iterations before I fully internalized <em>why</em> synaptic transmission reliability (0.85) dominates the coherence penalty (see Example 3 in Refinement Loop for detailed analysis). The AI’s “clean” assumptions obscured the biological insight that stochastic synaptic release is both a constraint <em>and</em> a security feature — understanding this required returning to primary neuroscience literature and reasoning through the exponential compounding effect myself.</li>
<li>Some nuances only became clear when I had to explain AI errors</li>
</ul>
<p><strong>Mitigation Strategy:</strong></p>
<ul>
<li>Mandatory “explain it without AI” check for core concepts</li>
<li>Periodic manual writing sessions to maintain voice and reasoning skills</li>
<li>Deliberate engagement with primary sources, not just AI summaries</li>
</ul>
<hr>
<h2 id="tool-disclosure">Tool Disclosure</h2>
<h3 id="ai-tools-used">AI Tools Used</h3>





















































<table><thead><tr><th>Tool</th><th>Version/Model</th><th>Use Case</th><th>Contribution Level</th></tr></thead><tbody><tr><td>ChatGPT (OpenAI)</td><td>GPT-4 / GPT-4o</td><td><strong>Week 1 (mid-Jan 2026)</strong> — idea bouncing, initial concept exploration. Used to externalize and stress-test framework ideas the author had been developing for years.</td><td>Exploratory (Week 1)</td></tr><tr><td>Claude (Anthropic)</td><td>Claude Opus 4.5</td><td>Code assistance, documentation drafting, research synthesis, co-derivation of hourglass model. <strong>Primary tool from repo creation (2026-01-18) onward.</strong></td><td>Primary</td></tr><tr><td>Claude Code</td><td>CLI</td><td>Repository management, file operations, git workflows, agent orchestration</td><td>Primary</td></tr><tr><td>Claude Research Agents</td><td>3 specialized (quantum physics, neuroscience, cybersecurity)</td><td>Validation of v3.1 architecture against 102 external sources</td><td>Validation</td></tr><tr><td>Gemini (Google)</td><td>Gemini 2.5 (CLI)</td><td><strong>Independent peer review and validation</strong> — full whitepaper critique with no prior context, framework stress-testing, TARA mechanism validation, NISS scoring review, email/communications review, and cross-AI validation of architectural decisions</td><td>Validation (Primary)</td></tr><tr><td>Gemini (Google)</td><td>Gemini 1.5/2.0</td><td>Research verification, cross-model validation, alternative perspectives, early concept validation</td><td>Validation (Secondary)</td></tr><tr><td>LMArena (LMSYS)</td><td>Blind comparison</td><td>Unbiased initial concept exploration, cross-model validation</td><td>Exploratory</td></tr></tbody></table>
<p><strong>Note on Multi-Model Approach</strong>: Using multiple AI models serves as a form of epistemic hygiene — cross-referencing outputs between ChatGPT, DeepSeek, Gemini, Claude, and blind comparisons via LMArena helps identify model-specific biases or hallucinations. When models disagree, human judgment adjudicates by consulting primary sources.</p>
<p><strong>Note on Chronological Progression</strong>: Before the repository was created, the author used ChatGPT during the first week (mid-January 2026) to bounce ideas and externalize a framework vision that had been forming over years of thinking about BCI security, neuroscience, and quantum mechanics. Claude became the primary tool from repo creation (2026-01-18) onward, handling implementation, documentation, and co-derivation of the mathematical framework. For the complete timestamped timeline of every AI interaction, see the <a href="../../../drafts/ai-working/QIF-DERIVATION-LOG.md#ai-collaboration-timeline">AI Collaboration Timeline in QIF-DERIVATION-LOG.md</a>.</p>
<p><strong>Note on Cross-AI Validation (added 2026-02-02)</strong>: To counteract potential confirmation bias from the primary development AI (Claude), significant framework changes now trigger an independent review by a different AI system (Gemini 2.5 via CLI). The reviewing AI receives the full whitepaper with no prior context and is instructed to provide unsoftened criticism. This is formalized in the <a href="../../../drafts/ai-working/PROPAGATION.md">Validation Pipeline</a> (Section E). Results are logged in the <a href="../../../drafts/ai-working/QIF-DERIVATION-LOG.md">Derivation Log</a>.</p>
<p><strong>Note on Automatic Documentation (added 2026-02-03)</strong>: All multi-AI validation sessions, architectural reviews, and significant framework decisions are now <strong>automatically documented</strong> in both the Derivation Log and this Transparency Statement at the time they occur. This includes: which AI systems were involved, what roles they played, what the human decided vs. what AI suggested, and the rationale for the decision. This practice is mandatory for all future sessions — not retroactive documentation, but real-time audit trail creation.</p>
<h3 id="cross-ai-validation-sessions">Cross-AI Validation Sessions</h3>

































<table><thead><tr><th>Date</th><th>Topic</th><th>AI Systems</th><th>Human Decision</th><th>Derivation Log</th></tr></thead><tbody><tr><td>2026-02-02</td><td>QIF v3.1 whitepaper review</td><td>Gemini 2.5 (independent critique)</td><td>Accepted structural feedback, rejected some scope suggestions</td><td>Entry #16</td></tr><tr><td>2026-02-03</td><td>QIF L8 positioning + L14 consciousness scope</td><td>Gemini 2.5 (independent review) + Claude Opus 4.5 (research agent) + Aurora (synthesis)</td><td>PENDING — awaiting results</td><td>Entry #20</td></tr><tr><td>2026-02-03</td><td>NIST CSF adoption for project structure</td><td>Claude Opus 4.5 (proposed mapping)</td><td>Kevin selected NIST over Kill Chain and STRIDE</td><td>Entry #21</td></tr></tbody></table>
<h3 id="non-ai-tools">Non-AI Tools</h3>
<ul>
<li>Python 3.9+ for implementation</li>
<li>pytest for testing</li>
<li>GitHub Actions for CI/CD</li>
<li>Standard scientific Python stack (no AI libraries in core package)</li>
</ul>
<hr>
<h2 id="commit-convention">Commit Convention</h2>
<p>All commits involving AI assistance include:</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>Co-Authored-By: Claude Opus 4.5 &#x3C;noreply@anthropic.com></span></span></code></pre>
<p>This provides a historical audit trail of all changes requested by the HITL (human-in-the-layer). Commits without this tag represent manual changes made within the Github UI.</p>
<h3 id="enhanced-commit-format-adopted-january-2026">Enhanced Commit Format (Adopted January 2026)</h3>
<p>For significant contributions, commits may include cognitive boundary metadata:</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>[Domain] Brief description</span></span>
<span class="line"><span></span></span>
<span class="line"><span>Original conception: Human/AI/Joint</span></span>
<span class="line"><span>Implementation: Human/AI-assisted</span></span>
<span class="line"><span>Verification: Human (method)</span></span>
<span class="line"><span></span></span>
<span class="line"><span>- Detailed changes</span></span>
<span class="line"><span>- Human decisions noted</span></span>
<span class="line"><span>- AI suggestions accepted/rejected noted</span></span>
<span class="line"><span></span></span>
<span class="line"><span>Co-Authored-By: Claude Opus 4.5 &#x3C;noreply@anthropic.com></span></span></code></pre>
<hr>
<h2 id="alignment-with-responsible-ai-principles">Alignment with Responsible AI Principles</h2>
<h3 id="transparency">Transparency</h3>
<ul>
<li>This document exists</li>
<li>AI contributions explicitly marked</li>
<li>Refinement loop documented with specific examples</li>
</ul>
<h3 id="accountability">Accountability</h3>
<ul>
<li>Human author (Kevin L. Qi) takes full responsibility for all published content</li>
<li>AI is a tool, not a co-author with independent standing</li>
<li>Errors in final output are human responsibility regardless of origin</li>
</ul>
<h3 id="human-oversight">Human Oversight</h3>
<ul>
<li>All AI output subject to human review before publication</li>
<li>Security-critical decisions made by human judgment</li>
<li>Rejection/modification rate demonstrates active oversight</li>
</ul>
<h3 id="explainability">Explainability</h3>
<ul>
<li>The QIF Framework itself embodies XAI principles (every firewall decision has traceable reasoning)</li>
<li>This document explains <em>how</em> AI was used, not just <em>that</em> it was used</li>
</ul>
<hr>
<h2 id="for-academic-review">For Academic Review</h2>
<p>This transparency statement is provided for:</p>
<ul>
<li>Graduate program admissions review</li>
<li>Academic integrity assessment</li>
<li>Responsible AI methodology evaluation</li>
</ul>
<h3 id="key-takeaways-for-reviewers">Key Takeaways for Reviewers</h3>
<ol>
<li><strong>Cognitive Autonomy Maintained</strong>: Original ideas, security architecture, and ethical reasoning are human contributions</li>
<li><strong>Critical Engagement Demonstrated</strong>: 40% of AI suggestions modified or rejected</li>
<li><strong>Verification Performed</strong>: All claims traced to sources; code tested</li>
<li><strong>Meta-Awareness Present</strong>: The author analyzed their own human-AI cognitive boundary as a neuroethics exercise</li>
</ol>
<hr>
<h2 id="document-maintenance">Document Maintenance</h2>
<p>This document is updated whenever:</p>
<ul>
<li>New publications are added to the repository</li>
<li>Significant AI-assisted development occurs</li>
<li>Methodology changes</li>
</ul>
<p>Update log maintained in git history.</p>
<hr>
<h2 id="contact">Contact</h2>
<p>For questions about this transparency statement or the human-AI collaboration methodology:</p>
<p><strong>Author</strong>: Kevin L. Qi
<strong>Repository</strong>: <a href="https://github.com/qinnovates/qinnovate">https://github.com/qinnovates/qinnovate</a>
<strong>Support This Research</strong>: <a href=".github/FUNDING.yml">Funding &#x26; Sponsorship</a></p>
<hr>
<p><em>This transparency statement itself was drafted with AI assistance for structure and formatting. The content, examples, and methodological decisions are human contributions.</em></p>
<hr>
<p>← Back to <a href="../INDEX.md">INDEX.md</a> | <a href="NEUROETHICS_ALIGNMENT.md">NEUROETHICS_ALIGNMENT.md</a> | <a href="REGULATORY_COMPLIANCE.md">REGULATORY_COMPLIANCE.md</a></p> </div> <footer class="mt-16 pt-8 border-t border-[var(--color-border)]"> <a href="/governance/" class="text-sm text-[var(--color-accent-primary)] hover:text-[var(--color-accent-secondary)] transition-colors">
&larr; All governance documents
</a> </footer> </article> <footer class="border-t border-[var(--color-border)] mt-24 relative overflow-hidden" data-astro-cid-sz7xmlte> <!-- Background brand mark --> <div class="footer-brand-bg select-none pointer-events-none" aria-hidden="true" data-astro-cid-sz7xmlte> <span class="footer-brand font-bold font-[family-name:var(--font-heading)] leading-none bg-gradient-to-r from-[var(--color-accent-primary)] via-[var(--color-accent-secondary)] to-[var(--color-accent-tertiary)] bg-clip-text text-transparent" data-astro-cid-sz7xmlte>
QINNOVATE
</span> </div> <div class="relative z-10 max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-16" data-astro-cid-sz7xmlte> <div class="grid grid-cols-2 md:grid-cols-4 gap-8" data-astro-cid-sz7xmlte> <!-- Brand column --> <div class="col-span-2 md:col-span-1" data-astro-cid-sz7xmlte> <a href="/" class="text-xl font-bold font-[family-name:var(--font-heading)] text-[var(--color-text-primary)]" data-astro-cid-sz7xmlte>
Qinnovate Neural Alliance
</a> <p class="mt-3 text-sm text-[var(--color-text-muted)] leading-relaxed" data-astro-cid-sz7xmlte>
Introducing the heart of neurotechnology, starting governed by neuroethics and neurosecurity principles.
</p> <p class="mt-4 text-xs text-[var(--color-text-faint)]" data-astro-cid-sz7xmlte>
QIF v6.0 Hourglass &middot; Open Framework
</p> </div> <div data-astro-cid-sz7xmlte> <h3 class="text-sm font-semibold text-[var(--color-text-primary)] uppercase tracking-wider mb-4" data-astro-cid-sz7xmlte> Technology </h3> <ul class="space-y-3" data-astro-cid-sz7xmlte> <li data-astro-cid-sz7xmlte> <a href="/framework/" class="text-sm text-[var(--color-text-muted)] hover:text-[var(--color-accent-primary)] transition-colors" data-astro-cid-sz7xmlte> QIF Framework </a> </li><li data-astro-cid-sz7xmlte> <a href="/nsp/" class="text-sm text-[var(--color-text-muted)] hover:text-[var(--color-accent-primary)] transition-colors" data-astro-cid-sz7xmlte> NSP Protocol </a> </li><li data-astro-cid-sz7xmlte> <a href="/runemate/" class="text-sm text-[var(--color-text-muted)] hover:text-[var(--color-accent-primary)] transition-colors" data-astro-cid-sz7xmlte> Project Runemate </a> </li><li data-astro-cid-sz7xmlte> <a href="/TARA/" class="text-sm text-[var(--color-text-muted)] hover:text-[var(--color-accent-primary)] transition-colors" data-astro-cid-sz7xmlte> TARA Atlas </a> </li><li data-astro-cid-sz7xmlte> <a href="/scoring/" class="text-sm text-[var(--color-text-muted)] hover:text-[var(--color-accent-primary)] transition-colors" data-astro-cid-sz7xmlte> NISS Scoring </a> </li> </ul> </div><div data-astro-cid-sz7xmlte> <h3 class="text-sm font-semibold text-[var(--color-text-primary)] uppercase tracking-wider mb-4" data-astro-cid-sz7xmlte> Resources </h3> <ul class="space-y-3" data-astro-cid-sz7xmlte> <li data-astro-cid-sz7xmlte> <a href="/news/" class="text-sm text-[var(--color-text-muted)] hover:text-[var(--color-accent-primary)] transition-colors" data-astro-cid-sz7xmlte> News </a> </li><li data-astro-cid-sz7xmlte> <a href="/lab/" class="text-sm text-[var(--color-text-muted)] hover:text-[var(--color-accent-primary)] transition-colors" data-astro-cid-sz7xmlte> QIF Lab </a> </li><li data-astro-cid-sz7xmlte> <a href="/rss.xml" class="text-sm text-[var(--color-text-muted)] hover:text-[var(--color-accent-primary)] transition-colors" data-astro-cid-sz7xmlte> RSS Feed </a> </li> </ul> </div><div data-astro-cid-sz7xmlte> <h3 class="text-sm font-semibold text-[var(--color-text-primary)] uppercase tracking-wider mb-4" data-astro-cid-sz7xmlte> Connect </h3> <ul class="space-y-3" data-astro-cid-sz7xmlte> <li data-astro-cid-sz7xmlte> <a href="https://github.com/qinnovates" class="text-sm text-[var(--color-text-muted)] hover:text-[var(--color-accent-primary)] transition-colors" target="_blank" rel="noopener noreferrer" data-astro-cid-sz7xmlte> GitHub </a> </li><li data-astro-cid-sz7xmlte> <a href="https://medium.com/@qikevinl" class="text-sm text-[var(--color-text-muted)] hover:text-[var(--color-accent-primary)] transition-colors" target="_blank" rel="noopener noreferrer" data-astro-cid-sz7xmlte> Medium </a> </li><li data-astro-cid-sz7xmlte> <a href="/about/" class="text-sm text-[var(--color-text-muted)] hover:text-[var(--color-accent-primary)] transition-colors" data-astro-cid-sz7xmlte> About </a> </li><li data-astro-cid-sz7xmlte> <a href="/advisory/" class="text-sm text-[var(--color-text-muted)] hover:text-[var(--color-accent-primary)] transition-colors" data-astro-cid-sz7xmlte> Advisory </a> </li><li data-astro-cid-sz7xmlte> <a href="/licensing/" class="text-sm text-[var(--color-text-muted)] hover:text-[var(--color-accent-primary)] transition-colors" data-astro-cid-sz7xmlte> Licensing </a> </li> </ul> </div> </div> <div class="mt-12 pt-8 flex flex-col sm:flex-row justify-between items-center gap-4" data-astro-cid-sz7xmlte> <p class="text-xs text-[var(--color-text-faint)]" data-astro-cid-sz7xmlte>
&copy; 2026 Qinnovate Neural Alliance. QIF is an open research framework.
</p> </div> </div> </footer>   <!-- Scroll-driven reveal observer --> <script type="module">function o(){const t=new IntersectionObserver(e=>{e.forEach(r=>{r.isIntersecting&&(r.target.classList.add("revealed"),t.unobserve(r.target))})},{threshold:.1,rootMargin:"0px 0px -40px 0px"});document.querySelectorAll(".reveal").forEach(e=>t.observe(e))}o();document.addEventListener("astro:after-swap",o);</script> </body> </html>