# LearnViz - Adaptive Learning Visualization Engine

> **Vision:** Visualizations that adapt to how *you* learn, not the other way around.

An AI-powered, local-first pipeline that transforms concepts into educational visualizations â€” with the goal of adapting to each individual's learning style, pace, and cognitive patterns.

---

## What Is LearnViz?

LearnViz generates educational visualizations from natural language concept descriptions. Unlike static educational content, LearnViz aims to become **adaptive** â€” learning how you learn and adjusting its output accordingly.

---

## Current Capabilities (v0.2)

### What Works NOW

| Feature | Status | Description |
|---------|--------|-------------|
| **Template-based Visualization** | âœ… Working | Pre-built animations for common concepts |
| **Concept Classification** | âœ… Working | Pattern matching to identify concept type |
| **Manim Rendering** | âœ… Working | Generate and render educational videos |
| **Voice Narration** | âœ… Working | TTS with edge-tts, gtts, or pyttsx3 |
| **Video + Audio Combining** | âœ… Working | Automatic merge with ffmpeg |
| **Web UI** | âœ… Working | Local Streamlit interface |
| **Ollama Integration** | âœ… Working | Custom AI-generated visualizations |

### Available Templates

These concepts have **high-quality, tested templates**:

| Template | What It Visualizes |
|----------|-------------------|
| `binary_search` | Step-by-step search with L/R pointers, elimination highlighting |
| `sorting` | Bubble/selection/insertion sort with bar chart representation |
| `pythagorean` | Theorem proof with squares on triangle sides |
| `tree_traversal` | Inorder/preorder/postorder with visit order display |
| `action_potential` | Neuron membrane depolarization, ion channels, voltage graph |
| `synapse` | Vesicle release, neurotransmitter diffusion, receptor binding |
| `motor_cortex_bci` | Electrode arrays, population coding, neural decoding |
| `neurotransmitter` | Dopamine, serotonin, norepinephrine pathways |

### Ollama Custom Generation

For concepts **without templates**, you can use a local LLM:

```bash
# Install Ollama first: https://ollama.ai
ollama pull llama3.2

# Generate custom visualization
python learnviz.py "How does TCP/IP work" --ollama --render
python learnviz.py "Explain photosynthesis" --ollama --ollama-model codellama --render
```

**Note:** Ollama-generated code may require manual fixes. Template-based visualizations are more reliable.

---

## NOT Yet Implemented (Future Work)

| Feature | Status | Target Version |
|---------|--------|----------------|
| **Learner Profiles** | ğŸ”² Planned | v0.4 |
| **Adaptive Pacing** | ğŸ”² Planned | v0.4 |
| **Interactive Mode** | ğŸ”² Planned | v0.5 |
| **Remotion Generator** | ğŸ”² Planned | v0.3 |
| **D3.js Generator** | ğŸ”² Planned | v0.3 |
| **Knowledge Graph** | ğŸ”² Planned | v0.4 |
| **Quiz Checkpoints** | ğŸ”² Planned | v0.5 |
| **Multi-language Support** | ğŸ”² Planned | v0.6 |

---

## Quick Start

### Installation

```bash
cd autodidactive/learnviz

# Install Python dependencies
pip install -r requirements.txt

# Install ffmpeg (required for video+audio)
brew install ffmpeg  # macOS
# or: apt install ffmpeg  # Linux

# Optional: Install Ollama for custom AI generation
# Download from https://ollama.ai
ollama pull llama3.2
```

### Web UI (Recommended)

```bash
python learnviz.py --ui
# Opens http://localhost:8501 (or next available port)
```

### Command Line

```bash
# Basic: Generate code only
python learnviz.py "Explain how binary search works"

# Full pipeline: Video + narration
python learnviz.py "Synaptic transmission" --render --tts edge-tts

# Custom AI generation (requires Ollama)
python learnviz.py "How does a compiler work" --ollama --render

# List available templates
python learnviz.py --list-templates

# Ollama setup help
python learnviz.py --ollama-setup
```

### CLI Options

| Flag | Description |
|------|-------------|
| `--render` | Render video after generating code |
| `--tts ENGINE` | Add voice narration (edge-tts, gtts, pyttsx3) |
| `--ollama` | Use Ollama for custom AI generation |
| `--ollama-model MODEL` | Specify Ollama model (default: llama3.2) |
| `--format FORMAT` | Output format: mp4 or gif |
| `--quality QUALITY` | Render quality: l, m, h, k |
| `--ui` | Launch web interface |
| `--interactive` | Refine plan before generation |

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    LEARNVIZ PIPELINE (v0.2)                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚   [User: "Explain binary search"]                               â”‚
â”‚          â”‚                                                      â”‚
â”‚          â–¼                                                      â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                              â”‚
â”‚   â”‚   ANALYZER   â”‚ â† Pattern matching (no AI needed)            â”‚
â”‚   â”‚              â”‚   Outputs: type, complexity, template        â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                              â”‚
â”‚          â”‚                                                      â”‚
â”‚          â–¼                                                      â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚   â”‚  GENERATOR   â”‚ â†â”€â”€ â”‚   OLLAMA     â”‚ â† For custom concepts   â”‚
â”‚   â”‚  (Templates) â”‚     â”‚   (Optional) â”‚   (local LLM)           â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â”‚          â”‚                                                      â”‚
â”‚          â–¼                                                      â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                              â”‚
â”‚   â”‚    MANIM     â”‚ â† Local render                               â”‚
â”‚   â”‚   RENDERER   â”‚   Outputs: MP4/GIF                           â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                              â”‚
â”‚          â”‚                                                      â”‚
â”‚          â–¼                                                      â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                              â”‚
â”‚   â”‚     TTS      â”‚ â† Voice narration                            â”‚
â”‚   â”‚  + FFMPEG    â”‚   Outputs: MP4 with audio                    â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                               â”‚
â”‚                                                                 â”‚
â”‚   [100% Local - No cloud required*]                             â”‚
â”‚   *edge-tts requires internet for voice synthesis               â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## How It Works (No Claude Required)

LearnViz runs **entirely locally** without any cloud AI services:

1. **Pattern Matching** (`analyzer.py`): Regex-based classification determines concept type
2. **Template Selection**: Maps concept to pre-built Manim templates
3. **Code Generation**: Fills template parameters OR uses local Ollama LLM
4. **Rendering**: Manim renders Python code to video locally
5. **Narration**: TTS generates audio, ffmpeg combines with video

**Users don't need Claude Code, OpenAI, or any API keys.**

---

## TTS Engines

| Engine | Quality | Requires Internet | Install |
|--------|---------|-------------------|---------|
| `edge-tts` | Best | Yes | `pip install edge-tts` |
| `gtts` | Good | Yes | `pip install gtts` |
| `pyttsx3` | Basic | No | `pip install pyttsx3` |

---

## File Structure

```
learnviz/
â”œâ”€â”€ README.md                 # This file
â”œâ”€â”€ learnviz.py               # Main CLI orchestrator
â”œâ”€â”€ analyzer.py               # Concept classification (pattern matching)
â”œâ”€â”€ ui.py                     # Streamlit web interface
â”œâ”€â”€ requirements.txt          # Python dependencies
â”‚
â”œâ”€â”€ generators/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ manim_gen.py          # Template-based Manim generator
â”‚   â”œâ”€â”€ narration.py          # TTS script generation
â”‚   â””â”€â”€ ollama_gen.py         # Ollama LLM integration
â”‚
â”œâ”€â”€ output/                   # Generated code and audio
â””â”€â”€ media/                    # Rendered videos (gitignored)
```

---

## Roadmap

### v0.2 (Current)
- âœ… Template-based visualization
- âœ… Ollama integration for custom concepts
- âœ… Voice narration pipeline
- âœ… Web UI

### v0.3 (Next)
- ğŸ”² More templates (graphs, recursion, linked lists)
- ğŸ”² Remotion generator (React-based video)
- ğŸ”² D3.js generator (interactive web)
- ğŸ”² Improved Ollama prompts

### v0.4 (Core Vision)
- ğŸ”² **Learner Profiles** - Track your learning style
- ğŸ”² **Adaptive Pacing** - Adjust to your speed
- ğŸ”² **Knowledge Graph** - Remember what you know
- ğŸ”² **Difficulty Calibration** - Match your level

### v0.5
- ğŸ”² Interactive mode (pause, rewind, ask questions)
- ğŸ”² Quiz checkpoints
- ğŸ”² Branching paths

### v1.0
- ğŸ”² Full adaptive learning engine
- ğŸ”² Community templates (opt-in)
- ğŸ”² Multi-language support

---

## Limitations

### Current Limitations

1. **Template Coverage**: Only ~10 templates available. Concepts without templates get generic or AI-generated visualizations.

2. **Ollama Quality**: AI-generated code may have errors and require manual fixes. Templates are more reliable.

3. **No Adaptation Yet**: The system doesn't learn your preferences or adjust to your pace (planned for v0.4).

4. **Manim Only**: Currently only generates Manim visualizations. D3.js and Remotion planned for v0.3.

5. **English Only**: Narration and templates are English-only.

### What This Is NOT

- âŒ Not a replacement for human teachers
- âŒ Not connected to any cloud AI (unless you count edge-tts)
- âŒ Not tracking your data (100% local)
- âŒ Not generating perfect code every time (especially with Ollama)

---

## Contributing

Contributions welcome! Priority areas:

1. **New Templates**: Add visualizations for more concepts
2. **Ollama Prompts**: Improve code generation quality
3. **Bug Fixes**: Especially in Manim rendering edge cases
4. **Documentation**: Examples, tutorials, translations

---

## Credits

Built on:
- [Manim Community](https://www.manim.community/) â€” Mathematical animations
- [Ollama](https://ollama.ai/) â€” Local LLM inference
- [Streamlit](https://streamlit.io/) â€” Web interface
- [edge-tts](https://github.com/rany2/edge-tts) â€” Text-to-speech

---

*Part of the ONI Framework â€” autodidact module*

> *"Learn how you learn, then learn faster."*
